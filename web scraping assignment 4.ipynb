{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9020ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: requests in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\naveen chopra\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9454c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from PIL import Image\n",
    "import io\n",
    "import re \n",
    "import requests\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b512012",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3020bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Naveen chopra\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07febea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3799e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank=[]\n",
    "\n",
    "try:\n",
    "    rank = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Rank.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('-')\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3bfc0311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Bath Song\"[15]',\n",
       " '\"Shape of You\"[16]',\n",
       " '\"See You Again\"[19]',\n",
       " '\"Phonics Song with Two Words\"[24]',\n",
       " '\"Wheels on the Bus\"[25]',\n",
       " '\"Uptown Funk\"[26]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[27]',\n",
       " '\"Gangnam Style\"[28]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[33]',\n",
       " '\"Dame Tu Cosita\"[34]',\n",
       " '\"Axel F\"[35]',\n",
       " '\"Sugar\"[36]',\n",
       " '\"Roar\"[37]',\n",
       " '\"Counting Stars\"[38]',\n",
       " '\"Sorry\"[39]',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " '\"Thinking Out Loud\"[41]',\n",
       " '\"Waka Waka (This Time for Africa)\"[42]',\n",
       " '\"Dark Horse\"[43]',\n",
       " '\"Lakdi Ki Kathi\"[44]',\n",
       " '\"Faded\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Let Her Go\"[47]',\n",
       " '\"Girls Like You\"[48]',\n",
       " '\"Humpty the train on a fruits ride\"[49]',\n",
       " '\"Lean On\"[50]',\n",
       " '\"Bailando\"[51]']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]'):\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    name.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    name.append('-')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79497a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'El Chombo',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Justin Bieber',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Shakira',\n",
       " 'Katy Perry',\n",
       " 'Jingle Toons',\n",
       " 'Alan Walker',\n",
       " 'Ed Sheeran',\n",
       " 'Passenger',\n",
       " 'Maroon 5',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs',\n",
       " 'Major Lazer',\n",
       " 'Enrique Iglesias']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_name=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]'):\n",
    "        artist_name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    artist_name.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    artist_name.append('-')\n",
    "artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dda8da3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'May 24, 2018',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'June 16, 2009',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 22, 2015',\n",
       " 'June 25, 2018',\n",
       " 'October 7, 2014',\n",
       " 'June 4, 2010',\n",
       " 'February 20, 2014',\n",
       " 'June 14, 2018',\n",
       " 'December 3, 2015',\n",
       " 'November 9, 2017',\n",
       " 'July 25, 2012',\n",
       " 'May 31, 2018',\n",
       " 'January 26, 2018',\n",
       " 'March 22, 2015',\n",
       " 'April 11, 2014']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    date.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    date.append('-')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d112f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "views=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]'):\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    views.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    views.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc8a5e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(name),len(artist_name),len(date),len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af02752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "      <th>VIEWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[19]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[24]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[25]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[26]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[27]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[28]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[33]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[34]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[36]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[37]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[38]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[41]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[47]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[50]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[51]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                                             NAME  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[19]   \n",
       "6    7.                \"Phonics Song with Two Words\"[24]   \n",
       "7    8.                          \"Wheels on the Bus\"[25]   \n",
       "8    9.                                \"Uptown Funk\"[26]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[27]   \n",
       "10  11.                              \"Gangnam Style\"[28]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[33]   \n",
       "12  13.                             \"Dame Tu Cosita\"[34]   \n",
       "13  14.                                     \"Axel F\"[35]   \n",
       "14  15.                                      \"Sugar\"[36]   \n",
       "15  16.                                       \"Roar\"[37]   \n",
       "16  17.                             \"Counting Stars\"[38]   \n",
       "17  18.                                      \"Sorry\"[39]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[40]   \n",
       "19  20.                          \"Thinking Out Loud\"[41]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "21  22.                                 \"Dark Horse\"[43]   \n",
       "22  23.                             \"Lakdi Ki Kathi\"[44]   \n",
       "23  24.                                      \"Faded\"[45]   \n",
       "24  25.                                    \"Perfect\"[46]   \n",
       "25  26.                                 \"Let Her Go\"[47]   \n",
       "26  27.                             \"Girls Like You\"[48]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[49]   \n",
       "28  29.                                    \"Lean On\"[50]   \n",
       "29  30.                                   \"Bailando\"[51]   \n",
       "\n",
       "                                      Artist_Name        UPLOAD DATE  VIEWS  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.85  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.16  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.70  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   6.20  \n",
       "4                                      Ed Sheeran   January 30, 2017   6.00  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.89  \n",
       "6                                       ChuChu TV      March 6, 2014   5.30  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   5.24  \n",
       "8                                     Mark Ronson  November 19, 2014   4.92  \n",
       "9                                     Miroshka TV  February 27, 2018   4.89  \n",
       "10                                            Psy      July 15, 2012   4.80  \n",
       "11                                     Get Movies   January 31, 2012   4.55  \n",
       "12                                      El Chombo      April 5, 2018   4.35  \n",
       "13                                     Crazy Frog      June 16, 2009   3.91  \n",
       "14                                       Maroon 5   January 14, 2015   3.87  \n",
       "15                                     Katy Perry  September 5, 2013   3.80  \n",
       "16                                    OneRepublic       May 31, 2013   3.79  \n",
       "17                                  Justin Bieber   October 22, 2015   3.66  \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   3.64  \n",
       "19                                     Ed Sheeran    October 7, 2014   3.60  \n",
       "20                                        Shakira       June 4, 2010   3.59  \n",
       "21                                     Katy Perry  February 20, 2014   3.52  \n",
       "22                                   Jingle Toons      June 14, 2018   3.48  \n",
       "23                                    Alan Walker   December 3, 2015   3.45  \n",
       "24                                     Ed Sheeran   November 9, 2017   3.45  \n",
       "25                                      Passenger      July 25, 2012   3.44  \n",
       "26                                       Maroon 5       May 31, 2018   3.42  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.41  \n",
       "28                                    Major Lazer     March 22, 2015   3.38  \n",
       "29                               Enrique Iglesias     April 11, 2014   3.38  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=pd.DataFrame({'RANK':Rank,'NAME':name, 'Artist_Name':artist_name,'UPLOAD DATE':date,'VIEWS':views})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832df5ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f84c2597",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22407c7e",
   "metadata": {},
   "source": [
    "2. Scrape the details teamIndia’sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8beea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d93ee986",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f42c11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "series=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div/ul/li[3]/a')\n",
    "series.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68ba6c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 Test(s)', '2 Test(s)', '2 Test(s)', '3 Test(s)']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match=[]\n",
    "title=driver.find_elements(By.XPATH,'//span[@class=\"match-card__format-name format__name-test ng-scope\"]')\n",
    "for i in title[1:]:\n",
    "    match.append(i.text)\n",
    "\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3402e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series=[]\n",
    "order=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in order[3:]:\n",
    "    series.append(i.text)\n",
    "    \n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdf337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place=[]\n",
    "stadium=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in stadium[1:]:\n",
    "    place.append(i.text.replace('(10.0 ov)',('')))\n",
    "    \n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8670e077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=[]\n",
    "dt=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "for i in dt[1:]:\n",
    "    date.append(i.text)\n",
    "    \n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66636633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=[]\n",
    "t=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "for i in t:\n",
    "    time.append(i.text)\n",
    "    \n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a9e201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATCH_TITLE</th>\n",
       "      <th>SERIES</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MATCH_TITLE, SERIES, PLACE, DATE, TIME]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2=pd.DataFrame({'MATCH_TITLE':match,'SERIES':series,'PLACE':place,'DATE':date,'TIME':time})\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88e9be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cee856b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec9db1a",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af61f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfb96bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42129db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "india=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0293318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "state.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1da34090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data1 sorting_1\"]'):\n",
    "    rank.append(i.text)\n",
    "    \n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0f609ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'India',\n",
       " 'Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Karnataka',\n",
       " 'Gujarat',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Telangana',\n",
       " 'Andhra Pradesh',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Jharkhand',\n",
       " 'Chhattisgarh',\n",
       " 'Uttarakhand',\n",
       " 'Himachal Pradesh',\n",
       " 'Jammu & Kashmir',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Manipur',\n",
       " 'Sikkim',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'India']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"name\"]'):\n",
    "    state.append(i.text)\n",
    "    \n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad716955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,332,992',\n",
       " '1,465,361',\n",
       " '1,404,761',\n",
       " '1,351,553',\n",
       " '1,322,936',\n",
       " '995,502',\n",
       " '845,247',\n",
       " '782,370',\n",
       " '776,140',\n",
       " '737,156',\n",
       " '707,542',\n",
       " '704,529',\n",
       " '666,075',\n",
       " '486,776',\n",
       " '472,506',\n",
       " '428,031',\n",
       " '282,782',\n",
       " '271,990',\n",
       " '266,537',\n",
       " '221,871',\n",
       " '133,303',\n",
       " '129,877',\n",
       " '66,060',\n",
       " '44,835',\n",
       " '37,571',\n",
       " '31,415',\n",
       " '29,544',\n",
       " '25,323',\n",
       " '25,141',\n",
       " '24,534',\n",
       " '22,488',\n",
       " '20,947',\n",
       " '-']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp_18_19=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]'):\n",
    "    gsdp_18_19.append(i.text)\n",
    "    \n",
    "gsdp_18_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b89683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,312,929',\n",
       " '1,166,817',\n",
       " '-',\n",
       " '1,156,039',\n",
       " '793,223',\n",
       " '711,627',\n",
       " '672,018',\n",
       " '663,258',\n",
       " '561,801',\n",
       " '-',\n",
       " '634,408',\n",
       " '572,240',\n",
       " '414,977',\n",
       " '418,868',\n",
       " '396,499',\n",
       " '-',\n",
       " '243,477',\n",
       " '240,036',\n",
       " '-',\n",
       " '-',\n",
       " '124,403',\n",
       " '63,408',\n",
       " '40,583',\n",
       " '-',\n",
       " '25,093',\n",
       " '26,695',\n",
       " '20,017',\n",
       " '20,673',\n",
       " '-',\n",
       " '-',\n",
       " '18,797',\n",
       " '-',\n",
       " '14,569,268',\n",
       " '1,794,123',\n",
       " '1,079,894',\n",
       " '979,159',\n",
       " '976,948',\n",
       " '1,036,859',\n",
       " '662,432',\n",
       " '600,433',\n",
       " '549,481',\n",
       " '550,584',\n",
       " '461,903',\n",
       " '513,322',\n",
       " '529,739',\n",
       " '477,834',\n",
       " '340,512',\n",
       " '354,830',\n",
       " '327,805',\n",
       " '207,193',\n",
       " '204,423',\n",
       " '200,453',\n",
       " '173,211',\n",
       " '101,534',\n",
       " '91,666',\n",
       " '51,878',\n",
       " '32,830',\n",
       " '27,565',\n",
       " '20,534',\n",
       " '21,779',\n",
       " '17,228',\n",
       " '15,972',\n",
       " '15,381',\n",
       " '15,013',\n",
       " '15,372',\n",
       " '-',\n",
       " '12,240,380']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp_19_20=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//td[7][@class=\"data\"]'):\n",
    "    gsdp_19_20.append(i.text)\n",
    "    \n",
    "gsdp_19_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "559e1635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-',\n",
       " '',\n",
       " '13.97%',\n",
       " '8.77%',\n",
       " '8.41%',\n",
       " '8.09%',\n",
       " '7.92%',\n",
       " '5.96%',\n",
       " '5.06%',\n",
       " '4.68%',\n",
       " '4.65%',\n",
       " '4.41%',\n",
       " '4.24%',\n",
       " '4.22%',\n",
       " '3.99%',\n",
       " '2.91%',\n",
       " '2.83%',\n",
       " '2.56%',\n",
       " '1.69%',\n",
       " '1.63%',\n",
       " '1.60%',\n",
       " '1.33%',\n",
       " '0.80%',\n",
       " '0.78%',\n",
       " '0.40%',\n",
       " '0.27%',\n",
       " '0.22%',\n",
       " '0.19%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.13%',\n",
       " '0.13%',\n",
       " '-',\n",
       " '']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//td[5][@class=\"data\"]'):\n",
    "    share.append(i.text)\n",
    "    \n",
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "beb17136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-',\n",
       " '2,869',\n",
       " '-',\n",
       " '1,167,776',\n",
       " '1,015,735',\n",
       " '1,035,131',\n",
       " '-',\n",
       " '713,376',\n",
       " '630,693',\n",
       " '594,806',\n",
       " '595,605',\n",
       " '496,798',\n",
       " '-',\n",
       " '568,265',\n",
       " '514,983',\n",
       " '377,276',\n",
       " '374,015',\n",
       " '344,437',\n",
       " '-',\n",
       " '218,232',\n",
       " '210,837',\n",
       " '-',\n",
       " '107,171',\n",
       " '-',\n",
       " '56,810',\n",
       " '35,980',\n",
       " '-',\n",
       " '22,291',\n",
       " '23,564',\n",
       " '18,549',\n",
       " '17,060',\n",
       " '-',\n",
       " '-',\n",
       " '17,797',\n",
       " '-',\n",
       " '12,681,246']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//td[6][@class=\"data\"]'):\n",
    "    gdp.append(i.text)\n",
    "    \n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2499d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 68 33 68 68 68\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(state),len(gsdp_18_19),len(gsdp_19_20),len(share),len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75c49b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>SHARE(18-19)</th>\n",
       "      <th>GDP $BILLION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,332,992</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,465,361</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,404,761</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,351,553</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,322,936</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>995,502</td>\n",
       "      <td>793,223</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>845,247</td>\n",
       "      <td>711,627</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>782,370</td>\n",
       "      <td>672,018</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>776,140</td>\n",
       "      <td>663,258</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>737,156</td>\n",
       "      <td>561,801</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>707,542</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>704,529</td>\n",
       "      <td>634,408</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>666,075</td>\n",
       "      <td>572,240</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>486,776</td>\n",
       "      <td>414,977</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>472,506</td>\n",
       "      <td>418,868</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>428,031</td>\n",
       "      <td>396,499</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>282,782</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>271,990</td>\n",
       "      <td>243,477</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>266,537</td>\n",
       "      <td>240,036</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>221,871</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>133,303</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>129,877</td>\n",
       "      <td>124,403</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>66,060</td>\n",
       "      <td>63,408</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>44,835</td>\n",
       "      <td>40,583</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>37,571</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>31,415</td>\n",
       "      <td>25,093</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>29,544</td>\n",
       "      <td>26,695</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,323</td>\n",
       "      <td>20,017</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>25,141</td>\n",
       "      <td>20,673</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>18,797</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                      2,332,992   \n",
       "1     2                 Tamil Nadu                      1,465,361   \n",
       "2     3              Uttar Pradesh                      1,404,761   \n",
       "3     4                    Gujarat                      1,351,553   \n",
       "4     5                  Karnataka                      1,322,936   \n",
       "5     6                West Bengal                        995,502   \n",
       "6     7                  Rajasthan                        845,247   \n",
       "7     8             Andhra Pradesh                        782,370   \n",
       "8     9                  Telangana                        776,140   \n",
       "9    10             Madhya Pradesh                        737,156   \n",
       "10   11                     Kerala                        707,542   \n",
       "11   12                      Delhi                        704,529   \n",
       "12   13                    Haryana                        666,075   \n",
       "13   14                      Bihar                        486,776   \n",
       "14   15                     Punjab                        472,506   \n",
       "15   16                     Odisha                        428,031   \n",
       "16   17                      Assam                        282,782   \n",
       "17   18               Chhattisgarh                        271,990   \n",
       "18   19                  Jharkhand                        266,537   \n",
       "19   20                Uttarakhand                        221,871   \n",
       "20   21            Jammu & Kashmir                        133,303   \n",
       "21   22           Himachal Pradesh                        129,877   \n",
       "22   23                        Goa                         66,060   \n",
       "23   24                    Tripura                         44,835   \n",
       "24   25                 Chandigarh                         37,571   \n",
       "25   26                 Puducherry                         31,415   \n",
       "26   27                  Meghalaya                         29,544   \n",
       "27   28                     Sikkim                         25,323   \n",
       "28   29                    Manipur                         25,141   \n",
       "29   30                   Nagaland                         24,534   \n",
       "30   31          Arunachal Pradesh                         22,488   \n",
       "31   32                    Mizoram                         20,947   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices SHARE(18-19) GDP $BILLION  \n",
       "0                               -       13.94%      399.921  \n",
       "1                       1,312,929        8.63%      247.629  \n",
       "2                       1,166,817        8.39%      240.726  \n",
       "3                               -        7.96%      228.290  \n",
       "4                       1,156,039        7.91%      226.806  \n",
       "5                         793,223        5.77%      165.556  \n",
       "6                         711,627        4.99%      143.179  \n",
       "7                         672,018        4.57%      131.083  \n",
       "8                         663,258        4.56%      130.791  \n",
       "9                         561,801        4.29%      122.977  \n",
       "10                              -        4.14%      118.733  \n",
       "11                        634,408        4.10%      117.703  \n",
       "12                        572,240        3.89%      111.519  \n",
       "13                        414,977        2.81%       80.562  \n",
       "14                        418,868        2.79%       79.957  \n",
       "15                        396,499        2.58%       74.098  \n",
       "16                              -        1.67%       47.982  \n",
       "17                        243,477        1.61%       46.187  \n",
       "18                        240,036        1.57%       45.145  \n",
       "19                              -        1.30%       37.351  \n",
       "20                              -        0.83%       23.690  \n",
       "21                        124,403        0.81%       23.369  \n",
       "22                         63,408        0.39%       11.115  \n",
       "23                         40,583        0.26%        7.571  \n",
       "24                              -        0.22%        6.397  \n",
       "25                         25,093        0.18%        5.230  \n",
       "26                         26,695        0.18%        5.086  \n",
       "27                         20,017        0.15%        4.363  \n",
       "28                         20,673        0.15%        4.233  \n",
       "29                              -        0.14%        4.144  \n",
       "30                              -        0.13%        3.737  \n",
       "31                         18,797        0.12%        3.385  \n",
       "32                              -            -            -  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3=pd.DataFrame({'RANK':rank[0:33],'STATE':state[0:33],'GSDP(18-19)- at current prices':gsdp_18_19[0:33],'GSDP(19-20)- at current prices':gsdp_19_20[0:33],'SHARE(18-19)':share[0:33],'GDP $BILLION':gdp[0:33]})\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ced5b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6e57d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f9969df",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b42f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "276afaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "signin=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/div/div[2]/a')\n",
    "signin.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "857722d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "username=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/main/div/div[4]/form/input[2]')\n",
    "username.send_keys('naveenchopra0402@gmail.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "001bf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "password=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/main/div/div[4]/form/div/input[1]')\n",
    "password.send_keys('babli@03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "789bf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "login=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/main/div/div[4]/form/div/input[12]')\n",
    "login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1426abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div[3]/nav/a[5]')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f9c6c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b21f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/geohot/tinygrad',\n",
       " 'https://github.com/artidoro/qlora',\n",
       " 'https://github.com/ShishirPatil/gorilla',\n",
       " 'https://github.com/TheMCHK/WindowsXPKg',\n",
       " 'https://github.com/gptlink/gptlink',\n",
       " 'https://github.com/SamurAIGPT/privateGPT',\n",
       " 'https://github.com/xorvoid/sectorc',\n",
       " 'https://github.com/vue-vine/vue-vine',\n",
       " 'https://github.com/freeCodeCamp/freeCodeCamp',\n",
       " 'https://github.com/microsoft/devicescript',\n",
       " 'https://github.com/dolphin-emu/dolphin',\n",
       " 'https://github.com/Neo-Desktop/WindowsXPKg',\n",
       " 'https://github.com/neetcode-gh/leetcode',\n",
       " 'https://github.com/CodinGame/SpringChallenge2023',\n",
       " 'https://github.com/OpenGVLab/InternGPT',\n",
       " 'https://github.com/xcanwin/KeepChatGPT',\n",
       " 'https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin',\n",
       " 'https://github.com/massgravel/Microsoft-Activation-Scripts',\n",
       " 'https://github.com/Liuhong99/Sophia',\n",
       " 'https://github.com/ZeroMemoryEx/Blackout',\n",
       " 'https://github.com/iperov/DeepFaceLive',\n",
       " 'https://github.com/AUTOMATIC1111/stable-diffusion-webui',\n",
       " 'https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor',\n",
       " 'https://github.com/commaai/openpilot',\n",
       " 'https://github.com/qbittorrent/qBittorrent']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=[]\n",
    "\n",
    "link=driver.find_elements(By.XPATH,'/html/body/div[1]/div[6]/main/div[3]/div/div[2]/article/h2/a')\n",
    "for i in link:\n",
    "    url.append(i.get_attribute('href'))\n",
    "    \n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70b6e5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geohot',\n",
       " 'artidoro',\n",
       " 'ShishirPatil',\n",
       " 'TheMCHK',\n",
       " 'gptlink',\n",
       " 'SamurAIGPT',\n",
       " 'xorvoid',\n",
       " 'vue-vine',\n",
       " 'freeCodeCamp',\n",
       " 'microsoft',\n",
       " 'dolphin-emu',\n",
       " 'Neo-Desktop',\n",
       " 'neetcode-gh',\n",
       " 'CodinGame',\n",
       " 'OpenGVLab',\n",
       " 'xcanwin',\n",
       " 'AbdullahAlfaraj',\n",
       " 'massgravel',\n",
       " 'Liuhong99',\n",
       " 'ZeroMemoryEx',\n",
       " 'iperov',\n",
       " 'AUTOMATIC1111',\n",
       " 'JushBJJ',\n",
       " 'commaai',\n",
       " 'qbittorrent']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_title=[]\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH,'//a[@class=\"url fn\"]')\n",
    "        repo_title.append(title.text)\n",
    "    except NoSuchElementException :\n",
    "        repo_title.append('-')\n",
    "        \n",
    "repo_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4066814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For something in between a pytorch and a karpathy/micrograd\\nThis may not be the best deep learning framework, but it is a deep learning framework.\\nThe sub 1000 line core of it is in tinygrad/\\nDue to its extreme simplicity, it aims to be the easiest framework to add new accelerators to, with support for both inference and training. Support the simple basic ops, and you get SOTA vision models/efficientnet.py and language models/transformer.py models.\\nWe are working on support for the Apple Neural Engine and the Google TPU in the accel/ folder. Eventually, we will build custom hardware for tinygrad, and it will be blindingly fast. Now, it is slow.\\nThis project is maintained by tiny corp.\\nInstallation\\ngit clone https://github.com/geohot/tinygrad.git\\ncd tinygrad\\npython3 -m pip install -e .\\nContributing\\nThere\\'s a lot of interest in tinygrad lately. Here\\'s some guidelines for contributing:\\nBugfixes are the best and always welcome! Like this one.\\nIf you don\\'t understand the code you are changing, don\\'t change it!\\nAll code golf PRs will be closed, but conceptual cleanups are great.\\nFeatures are welcome. Though if you are adding a feature, you need to include tests.\\nImproving test coverage is great, with reliable non brittle tests.\\nExample\\nfrom tinygrad.tensor import Tensor\\n\\nx = Tensor.eye(3, requires_grad=True)\\ny = Tensor([[2.0,0,-2.0]], requires_grad=True)\\nz = y.matmul(x).sum()\\nz.backward()\\n\\nprint(x.grad.numpy())  # dz/dx\\nprint(y.grad.numpy())  # dz/dy\\nSame example in torch\\nimport torch\\n\\nx = torch.eye(3, requires_grad=True)\\ny = torch.tensor([[2.0,0,-2.0]], requires_grad=True)\\nz = y.matmul(x).sum()\\nz.backward()\\n\\nprint(x.grad)  # dz/dx\\nprint(y.grad)  # dz/dy\\nIs tinygrad fast?\\nTry a matmul. See how, despite the style, it is fused into one kernel with the power of laziness.\\nDEBUG=3 OPTLOCAL=1 python3 -c \"from tinygrad.tensor import Tensor;\\nN = 1024; a, b = Tensor.randn(N, N), Tensor.randn(N, N);\\nc = (a.reshape(N, 1, N) * b.permute(1,0).reshape(1, N, N)).sum(axis=2);\\nprint((c.numpy() - (a.numpy() @ b.numpy())).mean())\"\\nChange to DEBUG=4 to see the generated code.\\nNeural networks?\\nIt turns out, a decent autograd tensor library is 90% of what you need for neural networks. Add an optimizer (SGD, Adam, AdamW implemented) from tinygrad.nn.optim, write some boilerplate minibatching code, and you have all you need.\\nNeural network example (from test/models/test_mnist.py)\\nfrom tinygrad.tensor import Tensor\\nimport tinygrad.nn.optim as optim\\n\\nclass TinyBobNet:\\n  def __init__(self):\\n    self.l1 = Tensor.uniform(784, 128)\\n    self.l2 = Tensor.uniform(128, 10)\\n\\n  def forward(self, x):\\n    return x.dot(self.l1).relu().dot(self.l2).log_softmax()\\n\\nmodel = TinyBobNet()\\noptim = optim.SGD([model.l1, model.l2], lr=0.001)\\n\\n# ... and complete like pytorch, with (x,y) data\\n\\nout = model.forward(x)\\nloss = out.mul(y).mean()\\noptim.zero_grad()\\nloss.backward()\\noptim.step()\\nGPU and Accelerator Support\\ntinygrad supports GPUs through PyOpenCL.\\nfrom tinygrad.tensor import Tensor\\n(Tensor.ones(4,4).gpu() + Tensor.ones(4,4).gpu()).cpu()\\nhlops (in tensor.py)\\nhlops are syntactic sugar around mlops. They support most things torch does.\\nmlops\\nmlops are mid level ops. They understand derivatives. They are very simple.\\nRelu, Log, Exp, Sin                            # unary ops\\nSum, Max                                       # reduce ops (with axis argument)\\nMaximum, Add, Sub, Mul, Pow, Div, Equal        # binary ops (no broadcasting, use expand)\\nExpand, Reshape, Permute, Pad, Shrink, Flip    # movement ops\\nYou no longer need to write mlops for a new accelerator\\nAdding an accelerator (llops)\\nThe autodiff stuff is all in mlops now so you can focus on the raw operations\\nBuffer                                                       # class of memory on this device\\nunary_op  (NOOP, EXP, LOG, CAST, SIN)                        # A -> A\\nreduce_op (SUM, MAX)                                         # A -> B (smaller size, B has 1 in shape)\\nbinary_op (ADD, SUB, MUL, DIV, POW, CMPEQ, MAX)              # A + A -> A (all the same size)\\nmovement_op (EXPAND, RESHAPE, PERMUTE, PAD, SHRINK, STRIDE)  # A -> B (different size)\\nfused_op [[optional]] (MULACC)                               # A * A -> B\\nImageNet inference\\nDespite being tiny, tinygrad supports the full EfficientNet. Pass in a picture to discover what it is.\\npython3 examples/efficientnet.py https://media.istockphoto.com/photos/hen-picture-id831791190\\nOr, if you have a webcam and cv2 installed\\npython3 examples/efficientnet.py webcam\\nPROTIP: Set \"DEBUG=2\" environment variable if you want to see why it\\'s slow.\\ntinygrad supports Stable Diffusion!\\nYou might need to download the weight of Stable Diffusion and put it into weights/\\nRun python3 examples/stable_diffusion.py\\n\"a horse sized cat eating a bagel\"\\ntinygrad supports LLaMA\\nAfter putting the weights in weights/LLaMA, you can have a chat with Stacy. She lives inside tinygrad.\\npython3 examples/llama.py\\ntinygrad supports GANs\\nSee examples/mnist_gan.py\\ntinygrad supports yolo\\nSee examples/yolov3.py\\nDrawing Execution Graph\\nGRAPH=1 python3 test/models/test_mnist.py TestMNIST.test_sgd_onestep\\n# requires dot, outputs /tmp/net.svg\\nRunning tests\\nFor more examples on how to run the full test suite please refer to the CI workflow.\\npython3 -m pip install -e \\'.[testing]\\'\\npython3 -m pytest\\npython3 -m pytest -v -k TestTrain\\npython3 ./test/models/test_train.py TestTrain.test_efficientnet',\n",
       " 'QLoRA: Efficient Finetuning of Quantized LLMs\\n| Paper | Adapter Weights | Demo |\\nThis repo supports the paper \"QLoRA: Efficient Finetuning of Quantized LLMs\", an effort to democratize access to LLM research.\\nQLoRA uses bitsandbytes for quantization and is integrated with Huggingface\\'s PEFT and transformers libraries. QLoRA was developed by members of the University of Washington\\'s UW NLP group.\\nOverview\\nWe present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters (LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimizers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. We release all of our models and code, including CUDA kernels for 4-bit training.\\nLicense and Intended Use\\nWe release the resources associated with QLoRA finetuning in this repository under MIT license. In addition, we release the Guanaco model family for base LLaMA model sizes of 7B, 13B, 33B, and 65B. These models are intended for purposes in line with the LLaMA license and require access to the LLaMA models.\\nDemo\\nGuanaco is a system purely intended for research purposes and could produce problematic outputs.\\nAccess the live demo here. Note this is the 33B model, the 65B model demo will come later.\\nOr host your own Guanaco gradio demo directly in Colab with this notebook. Works with free GPUs for 7B and 13B models.\\nAlternatively, can you distinguish ChatGPT from Guanaco? Give it a try! You can access the model response Colab here comparing ChatGPT and Guanaco 65B on Vicuna prompts.\\nInstallation\\nTo load models in 4bits with transformers and bitsandbytes, you have to install accelerate and transformers from source and make sure you have the latest version of the bitsandbytes library (0.39.0). You can achieve the above with the following commands:\\npip install -q -U bitsandbytes\\npip install -q -U git+https://github.com/huggingface/transformers.git\\npip install -q -U git+https://github.com/huggingface/peft.git\\npip install -q -U git+https://github.com/huggingface/accelerate.git\\nGetting Started\\nThe qlora.py code is a starting point for finetuning and inference on various datasets. Basic command for finetuning a baseline model on the Alpaca dataset:\\npython qlora.py --model_name_or_path <path_or_name>\\nFor models larger than 13B, we recommend adjusting the learning rate:\\npython qlora.py –learning_rate 0.0001 --model_name_or_path <path_or_name>\\nQuantization\\nQuantization parameters are controlled from the BitsandbytesConfig (see HF documenation) as follows:\\nLoading in 4 bits is activated through load_in_4bit\\nThe datatype used for the linear layer computations with bnb_4bit_compute_dtype\\nNested quantization is activated through bnb_4bit_use_double_quant\\nThe datatype used for qunatization is specified with bnb_4bit_quant_type. Note that there are two supported quantization datatypes fp4 (four bit float) and nf4 (normal four bit float). The latter is theoretically optimal for normally distributed weights and we recommend using nf4.\\n    model = AutoModelForCausalLM.from_pretrained(\\n        model_name_or_path=\\'/name/or/path/to/your/model\\',\\n        load_in_4bit=True,\\n        device_map=\\'auto\\',\\n        max_memory=max_memory,\\n        torch_dtype=torch.bfloat16,\\n        quantization_config=BitsAndBytesConfig(\\n            load_in_4bit=True,\\n            bnb_4bit_compute_dtype=torch.bfloat16,\\n            bnb_4bit_use_double_quant=True,\\n            bnb_4bit_quant_type=\\'nf4\\'\\n        ),\\n    )\\nPaged Optimizer\\nYou can access the paged optimizer with the argument --optim paged_adamw_32bit\\nTutorials and Demonstrations\\nHere is a blog discussing 4-bit quantization, QLoRA, and how they are integrated in transformers.\\nYou can host your own gradio Guanaco demo directly in Colab following this notebook. In addition, here are Colab notebooks with examples for inference and finetuning using QLoRA:\\nInference notebook\\nFinetuning notebook\\nOther examples are found under the examples/ folder.\\nSample Outputs\\nWe provide generations for the models described in the paper for both OA and Vicuna queries in the eval/generations folder. These are intended to foster further research on model evaluation and analysis.\\nCan you distinguish ChatGPT from Guanaco? Give it a try! You can access the model response Colab here comparing ChatGPT and Guanaco 65B on Vicuna prompts.\\nEvaluation\\nWe include scripts adapted from the FastChat repo to automatically evaluate model generations using GPT-4. We include script for comparisons relative to ChatGPT with scores out of 10 as well as \"pairwise comparisons\" with three class labeling (win, loose, or tie). These are found in the eval folder.\\nTo facilitate the replication of our evaluation and future work in this area, we release GPT-4 and human ratings of our systems. These are found under eval/ratings-human and eval/ratings-gpt4.\\nMore details can be found at eval/EVAL_README.md.\\nDataset for Guanaco\\nYou can find the dataset used to train Guanaco models on HF at timdettmers/openassistant-guanaco.\\nKnown Issues and Limitations\\nHere a list of known issues and bugs. If your issue is not reported here, please open a new issue and describe the problem.\\n4-bit inference is slow. Currently, our 4-bit inference implementation is not yet integrated with the 4-bit matrix multiplication\\nResuming a LoRA training run with the Trainer currently runs on an error\\nCurrently, using bnb_4bit_compute_type=\\'fp16\\' can lead to instabilities. For 7B LLaMA, only 80% of finetuning runs complete without error. We have solutions, but they are not integrated yet into bitsandbytes.\\nMake sure that tokenizer.bos_token_id = 1 to avoid generation issues.\\nCitation\\n@article{dettmers2023qlora,\\n  title={QLoRA: Efficient Finetuning of Quantized LLMs},\\n  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},\\n  journal={arXiv preprint arXiv:2305.14314},\\n  year={2023}\\n}\\nAcknowledgements\\nWe thank the Huggingface team, in particular Younes Belkada, for their support integrating QLoRA with PEFT and transformers libraries. We also thank Meta for releasing the LLaMA models without which this work would not have been possible.\\nThis repo builds on the Stanford Alpaca and LMSYS FastChat repos.',\n",
       " 'Gorilla: Large Language Model Connected with Massive APIs\\nBy Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez (Project Website)\\n🗞️ Checkout our paper!\\n👋 Join our Discord!\\n🚀 Try Gorilla in 60s\\nGorilla enables LLMs to use tools by invoking APIs. Given a natural language query, Gorilla comes up with the semantically- and syntactically- correct API to invoke. With Gorilla, we are the first to demonstrate how to use LLMs to invoke 1,600+ (and growing) API calls accurately while reducing hallucination. We also release APIBench, the largest collection of APIs, curated and easy to be trained on! Join us, as we try to expand the largest API store and teach LLMs how to write them! Hop on our Discord, or open a PR, or email us if you would like to have your API incorporated as well.\\nNews\\n🚀 [05/27] Released the first Gorilla model! and 🤗!\\n🔥 [05/27] We released the APIZoo contribution guide for community API contributions!\\n🔥 [05/25] We release the APIBench dataset and the evaluation code of Gorilla!\\nGet Started\\nInstall Dependencies\\nUse the following command to install dependencies. These are only for evaluation, additional dependencies for inference and training are in their respective sub-directories.\\nconda create -n gorilla python=3.8\\nconda activate gorilla\\npip install -r requirements.txt\\nWe have included prompts and responces for the APIBench with and without retrievers along with the Abstract Syntax Tree (AST) matching evaluation script at evaluation.\\nRepository Organization\\nOur repository organization is shown below.\\nThe data folder contains all the evaluation APIs (APIBench) and the community contributed APIs.\\nThe eval folder contains all our evaluation code as well as the Gorilla outputs.\\nThe inference folder contains all the inference code for running Gorilla locally.\\n[Coming Soon!] The train folder contains all the training code associated with Gorilla finetuning.\\nFor our dataset collections, all the 1640 API documentation is in data/api. We also include the APIBench dataset created by self-instruct in data/apibench. For evaluation, we convert this into a LLM-friendly chat format, and the questions are in eval/eval-data/questions, and the corresponding responces are in eval/eval-data/responses. We have also included the evaluation scripts are in eval/eval-scripts. This would be entirely sufficient to train Gorilla yourself, and reproduce our results. Please see evaluation for the details on how to use our evaluation pipeline.\\nAdditionally, to make it more accessible, we have also released the model weights gorilla-7b-hf-v0 that lets you invoke over 925 HuggingFace APIs. We will release TorchHub, TensorFlow, all three combined with generic chat capability and community contributed APIs as soon as we can scale infrastructure. You can run it locally from isntructions in the inference/ sub-directory, or we also provide a hosted Gorilla chat completion API! If you have any suggestions, or if you run into any issues please feel free to reach out to us either through Discord or email or raise a Github issue.\\ngorilla\\n├── data\\n│   ├── api (TF/HF/TH APIs used in generating apibench)\\n│   │   ├── {api_name}_api.jsonl\\n│   ├── apibench (Evaluating LLM models) v-1.0\\n│   │   ├── {api_name}_train.jsonl, {api_name}_eval.jsonl\\n|   |── apizoo (Contributed by the community - evolving)\\n│   |   ├── username1.json\\n│   │   ├── username2.json\\n│   │   ├── ...\\n├── eval\\n│   ├── README.md\\n│   ├── get_llm_responses.py\\n│   ├── eval-scripts\\n│   │   ├── ast_eval_{api_name}.py\\n│   ├── eval-data\\n│   │   ├── questions\\n│   │   │   ├── API name\\n│   │   │   │   ├── questions_{api_name}_{eval_metric}.jsonl\\n│   │   ├── responses\\n│   │   │   ├── API name\\n│   │   │   │   ├── responses_{api_name}_Gorilla_FT_{eval_metric}.jsonl\\n│   │   │   │   ├── responses_{api_name}_Gorilla_RT_{eval_metric}.jsonl\\n├── inference\\n├── train (Coming Soon!)\\nContributing Your API\\nWe aim to build an open-source, one-stop-shop for all APIs, LLMs can interact with! Any suggestions and contributions are welcome! Please see the details on how to contribute. THIS WILL ALWAYS REMAIN OPEN SOURCE.\\nFAQ(s)\\nI would like to use Gorilla commercially. Is there going to be a Apache 2.0 licensed version?\\nYes! We are actively working on it. We will release a Gorilla model with Apache 2.0 license by Jun 5. Please stay tuned, and let us know if you are interested.\\nCan we use Gorilla with Langchain, Toolformer, AutoGPT etc?\\nAbsolutely! You\\'ve highlighted a great aspect of our tools. Gorilla is an end-to-end model, specifically tailored to serve correct API calls without requiring any additional coding. It\\'s designed to work as part of a wider ecosystem and can be flexibly integrated with other tools.\\nLangchain, is a versatile developer tool. Its \"agents\" can efficiently swap in any LLM, Gorilla included, making it a highly adaptable solution for various needs.\\nAutoGPT, on the other hand, concentrates on the art of prompting GPT series models. It\\'s worth noting that Gorilla, as a fully fine-tuned model, consistently shows remarkable accuracy, and lowers hallucination, outperforming GPT-4 in making specific API calls.\\nNow, when it comes to ToolFormer, Toolformer zeroes in on a select set of tools, providing specialized functionalities. Gorilla, in contrast, has the capacity to manage thousands of API calls, offering a broader coverage over a more extensive range of tools.\\nThe beauty of these tools truly shines when they collaborate, complementing each other\\'s strengths and capabilities to create an even more powerful and comprehensive solution. This is where your contribution can make a difference. We enthusiastically welcome any inputs to further refine and enhance these tools.\\nProject Roadmap\\nIn the immediate future, we plan to release the following:\\nDataset and Eval Code\\nOpening up the APIZoo for contributions from community\\nHosted Gorilla LLM chat for HF model APIs [May 27, 2023]\\nRelease weights for HF model APIs [May 27, 2023]\\nRun Gorilla LLM locally [May 28, 2023]\\n[] Release weights for all APIs from APIBench [May 28, 2023]\\n[] Release a commercially usable, Apache 2.0 licensed Gorilla model [Jun 5, 2023]\\n[] Train a model with first batch of community contributed APIs from APIZoo [Jun 5, 2023]\\n[] Release training code [Jun 5, 2023]\\n[] Train SOTA Gorilla LLM with expanded APIBench and APIZoo 🚀\\nPropose a new task you would like to work on 🤩\\nCitation\\nIf you use Gorilla or APIBench, please cite our paper:\\n@article{patil2023gorilla,\\n  title={Gorilla: Large Language Model Connected with Massive APIs},\\n  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},\\n  year={2023},\\n  journal={arXiv preprint arXiv:2305.15334},\\n} ',\n",
       " 'Windows XP Keygen!\\nFAQ\\nWhat does it do?\\nThis program allows you to generate endless Windows XP keys. You also can use it to check your already existing keys.\\nHow does it work?\\nThis program is based on this paper Basically, it uses a cracked private key from Microsoft to sign some stuff encoded in the 25-digit product key. It also does this process in reverse to check for the validation of the keys.\\nHow do I use it?\\nIt all comes down to four simple steps:\\n1. Use this program to generate a key, and use such key during installation.\\n2. After installation, you will be prompted to activate Windows. Select the telephone activation method, then, fire up this website and enter the installation ID that the activation wizard gave you.\\n3. Click \"Next\"\\n4. Profit!\\nREQUIREMENTS:\\nOpenSSL >0.9.8b',\n",
       " 'GPTLink\\n只需简单几步，即可快速搭建可商用的 ChatGPT 站点。\\n体验地址 · 演示图片 · 反馈 · 微信加群\\n商务合作 · 关注公众号 · 打赏开发者\\n功能概览\\n支持 Docker 部署\\n开箱即用的控制台\\n完美适配移动端\\n自定义付费套餐\\n一键导出对话\\n任务拉新获客\\n开始使用\\n项目基于 PHP (Hyperf) + Vue 开发，推荐使用 Docker 进行部署；\\n准备好一个 API Key，推荐使用 GPTLINK Key；\\nGPTLINK Key ，注册完成之后进入个人中心申请开发者后获取 API Key，过程非常简单，无需审核，接口无需代理；\\nOpenAi 官方 Key；\\n微信相关资源（网站应用，微信公众号，微信支付），网站应用用于 PC 端扫码登录，公众号用于微信内网页登录，缺省情况将无法在对应渠道使用；\\n项目配置\\n项目提供有限的权限控制功能，项目配置文件位于 gptserver/.env，如诺不存在此文件，将 gptserver/.env.example 更名为 .env 作为配置项进行使用，详细的配置说明 点此查看\\n部署\\n项目支持多种部署方式，部署文档参考：点此查看\\nPHP 环境部署\\nDocker 部署\\nDocker Compose 部署\\n云主机镜像部署\\n访问\\n部署完成后访问 http://域名或IP 进入对话页面，/admin 路径访问管理页，管理员账号密码为配置项设置的 ADMIN_USERNAME 与 ADMIN_USERNAME ，如不传入，默认账号密码为 admin admin888\\n版本计划\\n兑换码\\nAI 生图\\n分销\\n对话记录\\n统计视图\\n参与贡献\\n我们深知这不是一个完美的产品，但是它只是一个开始，欢迎加入我们一起完善！❤️ 请参阅 贡献指南\\n特别鸣谢\\n@overtrue\\n@Lainy0307\\n疑难解答\\n常见问题汇总：点击查看\\n开源协议\\nApache License Version 2.0 see http://www.apache.org/licenses/LICENSE-2.0.html',\n",
       " 'PrivateGPT\\nInterrogate your documents without relying on the internet by utilizing the capabilities of local LLMs. Ensure complete privacy as none of your data ever leaves your local execution environment. Seamlessly process and inquire about your documents even without an internet connection. Inspired from imartinez\\nGetting started\\nCode is up, ⭐ (Star) the repo meanwhile to receive updates\\nFollow Anil Chandra Naidu Matcha & Ankur Singh on twitter for updates\\nRequirements\\nPython 3.8 or later\\nMinimum 16GB of memory\\nHow to run\\nGo to client folder and run the below commands\\nnpm install\\nnpm run dev\\nGo to server folder and run the below commands\\npip install -r requirements.txt\\npython privateGPT.py\\nOpen localhost:3000, click on download model to download the required model initially\\nUpload any document of your choice and click on Ingest data. Ingestion is fast\\nNow run any query on your data. Data querying is slow and thus wait for sometime\\nSupport\\nJoin our discord https://discord.gg/A6EzvsKX4u to get support\\nData\\nThe supported extensions for documents are:\\n.csv: CSV,\\n.docx: Word Document,\\n.enex: EverNote,\\n.eml: Email,\\n.epub: EPub,\\n.html: HTML File,\\n.md: Markdown,\\n.msg: Outlook Message,\\n.odt: Open Document Text,\\n.pdf: Portable Document Format (PDF),\\n.pptx : PowerPoint Document,\\n.txt: Text file (UTF-8),',\n",
       " 'SectorC\\nSectorC is a C compiler written in x86-16 assembly that fits within the 512 byte boot sector of an x86 machine. It supports a subset of C that is large enough to write real and interesting programs. It is quite likely the smallest C compiler ever written.\\nIn a base64 encoding, it looks like this:\\n6gUAwAdoADAfaAAgBzH/6DABPfQYdQXoJQHr8+gjAVOJP+gSALDDqluB+9lQdeAG/zdoAEAfy+gI\\nAegFAYnYg/hNdFuE9nQNsOiqiwcp+IPoAqvr4j3/FXUG6OUAquvXPVgYdQXoJgDrGj0C2nUGV+gb\\nAOsF6CgA68Ow6apYKfiD6AKrifgp8CaJRP7rrOg4ALiFwKu4D4Srq1fonP9ewz2N/HUV6JoA6BkA\\nieu4iQRQuIs26IAAWKvD6AcAieu4iQbrc4nd6HkA6HYA6DgAHg4fvq8Bra052HQGhcB19h/DrVCw\\nUKroWQDoGwC4WZGrW4D/wHUMuDnIq7i4AKu4AA+ridirH8M9jfx1COgzALiLBOucg/j4dQXorf/r\\nJIP49nUI6BwAuI0G6wyE0nQFsLiq6wa4iwarAduJ2KvrA+gAAOhLADwgfvkx2zHJPDkPnsI8IH4S\\nweEIiMFr2wqD6DABw+gqAOvqicg9Ly90Dj0qL3QSPSkoD5TGidjD6BAAPAp1+eu86Ln/g/jDdfjr\\nslIx9osEMQQ8O3QUuAACMdLNFIDkgHX0PDt1BIkEMcBaw/v/A8H9/yvB+v/34fb/I8FMAAvBLgAz\\nwYQA0+CaANP4jwCUwHf/lcAMAJzADgCfwIUAnsCZAJ3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAVao=\\nSupported language\\nA fairly large subset is supported: global variables, functions, if statements, while statements, lots of operators, pointer dereference, inline machine-code, comments, etc. All of these features make it quite capable.\\nFor example, the following program animates a moving sine-wave:\\nint y;\\nint x;\\nint x_0;\\nvoid sin_positive_approx()\\n{\\n  y = ( x_0 * ( 157 - x_0 ) ) >> 7;\\n}\\nvoid sin()\\n{\\n  x_0 = x;\\n  while( x_0 > 314 ){\\n    x_0 = x_0 - 314;\\n  }\\n  if( x_0 <= 157 ){\\n    sin_positive_approx();\\n  }\\n  if( x_0 > 157 ){\\n    x_0 = x_0 - 157;\\n    sin_positive_approx();\\n    y = 0 - y;\\n  }\\n  y = 100 + y;\\n}\\n\\n\\nint offset;\\nint x_end;\\nvoid draw_sine_wave()\\n{\\n  x = offset;\\n  x_end = x + 314;\\n  while( x <= x_end ){\\n    sin();\\n    pixel_x = x - offset;\\n    pixel_y = y;\\n    vga_set_pixel();\\n    x = x + 1;\\n  }\\n}\\n\\nint v_1;\\nint v_2;\\nvoid delay()\\n{\\n  v_1 = 0;\\n  while( v_1 < 50 ){\\n    v_2 = 0;\\n    while( v_2 < 10000 ){\\n      v_2 = v_2 + 1;\\n    }\\n    v_1 = v_1 + 1;\\n  }\\n}\\n\\nvoid main()\\n{\\n  vga_init();\\n\\n  offset = 0;\\n  while( 1 ){\\n    vga_clear();\\n    draw_sine_wave();\\n\\n    delay();\\n    offset = offset + 1;\\n    if( offset >= 314 ){ // mod the value to avoid 2^16 integer overflow\\n      offset = offset - 314;\\n    }\\n  }\\n}\\nScreenshot\\nProvided Example Code\\nA few examples are provided that leverage the unique hardware aspects of the x86-16 IBM PC:\\nexamples/hello.c: Print a text greeting on the screen writing to memory at 0xB8000\\nexamples/sinwave.c: Draw a moving sine wave animation with VGA Mode 0x13 using an appropriately bad approximation of sin(x)\\nexamples/twinkle.c: Play “Twinkle Twinkle Little Star” through the PC Speaker (Warning: LOUD)\\nGrammar\\nThe following grammar is accepted and compiled by sectorc:\\nprogram     = (var_decl | func_decl)+\\nvar_decl    = \"int\" identifier \";\"\\nfunc_decl   = \"void\" func_name \"{\" statement* \"}\"\\nfunc_name   = <identifier that ends in \"()\" with no space>\\nstatement   = \"if(\" expr \"){\" statement* \"}\"\\n            | \"while(\" expr \"){\" statement* \"}\"\\n            | \"asm\" integer \";\"\\n            | func_name \";\"\\n            | assign_expr \";\"\\nassign_expr = deref? identifier \"=\" expr\\nderef       = \"*(int*)\"\\nexpr        = unary (op unary)?\\nunary       = deref identifier\\n            | \"&\" identifier\\n            | \"(\" expr \")\"\\n            | indentifier\\n            | integer\\nop          = \"+\" | \"-\" | \"&\" | \"|\" | \"^\" | \"<<\" | \">>\"\\n            | \"==\" | \"!=\" | \"<\" | \">\" | \"<=\" | \">=\"\\nIn addition, both // comment and /* multi-line comment */ styles are supported.\\n(NOTE: This grammar is 704 bytes in ascii, 38% larger than it\\'s implementation!)\\nHow?\\nSee blog post: SectorC: A C Compiler in 512 bytes\\nWhy?\\nIn 2020, cesarblum wrote a Forth that fits in a bootsector: (sectorforth)\\nIn 2021, jart et. al. wrote a Lisp that fits in the bootsector: (sectorlisp)\\nNaturally, C always needs to come and crash (literally) every low-level systems party regaurdless of whether it was even invited.\\nRunning\\nDependencies:\\nnasm for assembling (I used v2.16.01)\\nqemu-system-i386 for emulating x86-16 (I used v8.0.0)\\nBuild: ./build.sh\\nRun: ./run.sh your_source.c\\nNOTE: Tested only on a MacBook M1\\nWhat is this useful for?\\nProbably Nothing.\\nOr at least that\\'s what I thought when starting out. But, I didn\\'t think I\\'d get such a feature set. Now, I\\'d say that it might be useful for someone that wants to explore x86-16 bios functions and machine model w/o having to learn lots of x86 assembly first. But, then again, you should just use a proper C compiler and write a tiny bootloader to execute it.',\n",
       " \"Vue Vine\\n中文 README\\nAnother style of writing Vue components.\\nWhy this ?\\nThere are many discussions in community that hopes for a solution that supports writing multiple Vue components in a single file. That's why Vue Vine was born.\\nVue vine was designed to provide more flexibility of managing Vue components. It is a parallel style to SFC.\\nTake a quick view:\\nGet started\\nwarning: For now, Vue Vine is still under heavily development, please don't use it in production.\\nYou can try the demo by following steps:\\ngit clone https://github.com/vue-vine/vue-vine.git\\ncd vue-vine\\npnpm install\\n\\n# Start watching the plugin's building\\npnpm run dev\\n\\n# Start Playground's Vite dev server\\npnpm run play\\nYou can see the demo in http://localhost:3333/.\\nYou can add URL query ?sfc to switch back to SFC style example.\\nYou can inspect the transforming process in http://localhost:3333/__inspect/\",\n",
       " \"freeCodeCamp.org's open-source codebase and curriculum\\nfreeCodeCamp.org is a friendly community where you can learn to code for free. It is run by a donor-supported 501(c)(3) charity to help millions of busy adults transition into tech. Our community has already helped more than 40,000 people get their first developer job.\\nOur full-stack web development and machine learning curriculum is completely free and self-paced. We have thousands of interactive coding challenges to help you expand your skills.\\nTable of Contents\\nCertifications\\nThe Learning Platform\\nReporting Bugs and Issues\\nReporting Security Issues and Responsible Disclosure\\nContributing\\nPlatform, Build and Deployment Status\\nLicense\\nCertifications\\nfreeCodeCamp.org offers several free developer certifications. Each of these certifications involves building 5 required web app projects, along with hundreds of optional coding challenges to help you prepare for those projects. We estimate that each certification will take a beginner programmer around 300 hours to earn.\\nEach of these 50 projects in the freeCodeCamp.org curriculum has its own agile user stories and automated tests. These help you build up your project incrementally and ensure you've fulfilled all the user stories before you submit it.\\nYou can pull in these test suites through freeCodeCamp's CDN. This means you can build these projects on websites like CodePen and Replit - or even on your local computer's development environment.\\nOnce you've earned a certification, you will always have it. You will always be able to link to it from your LinkedIn or resume. And when your prospective employers or freelance clients click that link, they'll see a verified certification specific to you.\\nThe one exception to this is if we discover violations of our Academic Honesty Policy. When we catch people unambiguously plagiarizing (submitting other people's code or projects as their own without citation), we do what all rigorous institutions of learning should do - we revoke their certifications and ban those people.\\nHere are our ten core certifications:\\n1. Responsive Web Design Certification\\nLearn HTML by Building a Cat Photo App\\nLearn Basic CSS by Building a Cafe Menu\\nLearn CSS Colors by Building a Set of Colored Markers\\nLearn HTML Forms by Building a Registration Form\\nLearn the CSS Box Model by Building a Rothko Painting\\nLearn CSS Flexbox by Building a Photo Gallery\\nLearn Typography by Building a Nutrition Label\\nLearn Accessibility by Building a Quiz\\nLearn More About CSS Pseudo Selectors By Building A Balance Sheet\\nLearn Intermediate CSS by Building a Picasso Painting\\nLearn Responsive Web Design by Building a Piano\\nLearn CSS Variables by Building a City Skyline\\nLearn CSS Grid by Building a Magazine\\nLearn CSS Transforms by Building a Penguin\\nLearn CSS Animations by Building a Ferris Wheel\\n\\nProjects: Survey Form, Tribute Page, Technical Documentation Page, Product Landing Page, Personal Portfolio Webpage\\n2. JavaScript Algorithms and Data Structures Certification\\nBasic JavaScript\\nES6\\nRegular Expressions\\nDebugging\\nBasic Data Structures\\nBasic Algorithm Scripting\\nObject-Oriented Programming\\nFunctional Programming\\nIntermediate Algorithm Scripting\\n\\nProjects: Palindrome Checker, Roman Numeral Converter, Caesar's Cipher, Telephone Number Validator, Cash Register\\n3. Front End Libraries Certification\\nBootstrap\\njQuery\\nSass\\nReact\\nRedux\\nReact and Redux\\n\\nProjects: Random Quote Machine, Markdown Previewer, Drum Machine, JavaScript Calculator, 25 + 5 Clock\\n4. Data Visualization Certification\\nData Visualization with D3\\nJSON APIs and Ajax\\n\\nProjects: Bar Chart, Scatterplot Graph, Heat Map, Choropleth Map, Treemap Diagram\\n5. APIs and Microservices Certification\\nManaging Packages with Npm\\nBasic Node and Express\\nMongoDB and Mongoose\\n\\nProjects: Timestamp Microservice, Request Header Parser, URL Shortener, Exercise Tracker, File Metadata Microservice\\n6. Quality Assurance Certification\\nQuality Assurance and Testing with Chai\\nAdvanced Node and Express\\n\\nProjects: Metric-Imperial Converter, Issue Tracker, Personal Library, Sudoku Solver, American British Translator\\n7. Scientific Computing with Python Certification\\nIntroduction to Python for Everybody\\n\\nProjects: Arithmetic Formatter, Time Calculator, Budget App, Polygon Area Calculator, Probability Calculator\\n8. Data Analysis with Python Certification\\nData Analysis with Python Course\\nNumPy\\n\\nProjects: Mean-Variance-Standard Deviation Calculator, Demographic Data Analyzer, Medical Data Visualizer, Page View Time Series Visualizer, Sea Level Predictor\\n9. Information Security Certification\\nInformation Security with HelmetJS\\nPython for Penetration Testing\\n\\nProjects: Stock Price Checker, Anonymous Message Board, Port Scanner, SHA-1 Password Cracker, Secure Real Time Multiplayer Game\\n10. Machine Learning with Python Certification\\nTensorFlow\\nHow Neural Networks Work\\n\\nProjects: Rock Paper Scissors, Cat and Dog Image Classifier, Book Recommendation Engine using KNN, Linear Regression Health Costs Calculator, Neural Network SMS Text Classifier\\nLegacy Full Stack Development Certification\\nOnce you have earned the Responsive Web Design, Algorithms and Data Structures, Front End Development Libraries, Data Visualization, Back End Development and APIs, and Legacy Information Security and Quality Assurance certifications, you'll be able to claim your freeCodeCamp.org Full Stack Development Certification. This distinction signifies that you've completed around 1,800 hours of coding with a wide range of web development tools.\\nLegacy Certifications\\nWe also have 4 legacy certifications dating back to our 2015 curriculum, which are still available. All of the required projects for these legacy certifications will remain available on freeCodeCamp.org.\\nLegacy Front End Development Certification\\nLegacy Data Visualization Certification\\nLegacy Back End Development Certification\\nLegacy Information Security and Quality Assurance Certification\\nThe Learning Platform\\nThis code is running live at freeCodeCamp.org.\\nOur community also has:\\nA forum where you can usually get programming help or project feedback within hours.\\nA YouTube channel with free courses on Python, SQL, Android, and a wide variety of other technologies.\\nA technical publication with thousands of programming tutorials and articles about mathematics and computer science.\\nA Discord server where you can hang out and talk with developers and people who are learning to code.\\nJoin the community here.\\nReporting Bugs and Issues\\nIf you think you've found a bug, first read the how to report a bug article and follow its instructions.\\nIf you're confident it's a new bug and have confirmed that someone else is facing the same issue, go ahead and create a new GitHub issue. Be sure to include as much information as possible so we can reproduce the bug.\\nReporting Security Issues and Responsible Disclosure\\nWe appreciate responsible disclosure of vulnerabilities that might impact the integrity of our platforms and users.\\nRead our security policy and follow these steps to report a vulnerability.\\nContributing\\nThe freeCodeCamp.org community is possible thanks to thousands of kind volunteers like you. We welcome all contributions to the community and are excited to welcome you aboard.\\nPlease follow these steps to contribute.\\nPlatform, Build, and Deployment Status\\nThe general platform status for all our applications is available at status.freecodecamp.org. The build and deployment status for the code is available in our DevOps Guide.\\nLicense\\nCopyright © 2023 freeCodeCamp.org\\nThe content of this repository is bound by the following licenses:\\nThe computer software is licensed under the BSD-3-Clause license.\\nThe learning resources in the /curriculum directory including their subdirectories thereon are licensed under the CC-BY-SA-4.0 license.\",\n",
       " \"DeviceScript\\nTypeScript for Tiny IoT Devices.\\nDeviceScript brings a professional TypeScript developer experience to low-resource microcontroller-based devices. DeviceScript is compiled to a custom VM bytecode, which can run in very constrained environments.\\nRead the documentation\\n** Technical Preview - Join the discussions to provide feedback. **\\nblinky.mp4\\nContributing\\nContributions are welcome! See contributing page.\\nTrademarks\\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\",\n",
       " 'Dolphin - A GameCube and Wii Emulator\\nHomepage | Project Site | Buildbot | Forums | Wiki | GitHub Wiki | Issue Tracker | Coding Style | Transifex Page\\nDolphin is an emulator for running GameCube and Wii games on Windows, Linux, macOS, and recent Android devices. It\\'s licensed under the terms of the GNU General Public License, version 2 or later (GPLv2+).\\nPlease read the FAQ before using Dolphin.\\nSystem Requirements\\nDesktop\\nOS\\nWindows (10 or higher).\\nLinux.\\nmacOS (10.15 Catalina or higher).\\nUnix-like systems other than Linux are not officially supported but might work.\\nProcessor\\nA CPU with SSE2 support.\\nA modern CPU (3 GHz and Dual Core, not older than 2008) is highly recommended.\\nGraphics\\nA reasonably modern graphics card (Direct3D 11.1 / OpenGL 3.3).\\nA graphics card that supports Direct3D 11.1 / OpenGL 4.4 is recommended.\\nAndroid\\nOS\\nAndroid (5.0 Lollipop or higher).\\nProcessor\\nA processor with support for 64-bit applications (either ARMv8 or x86-64).\\nGraphics\\nA graphics processor that supports OpenGL ES 3.0 or higher. Performance varies heavily with driver quality.\\nA graphics processor that supports standard desktop OpenGL features is recommended for best performance.\\nDolphin can only be installed on devices that satisfy the above requirements. Attempting to install on an unsupported device will fail and display an error message.\\nBuilding for Windows\\nUse the solution file Source/dolphin-emu.sln to build Dolphin on Windows. Dolphin targets the latest MSVC shipped with Visual Studio or Build Tools. Other compilers might be able to build Dolphin on Windows but have not been tested and are not recommended to be used. Git and latest Windows SDK must be installed when building.\\nMake sure to pull submodules before building:\\ngit submodule update --init\\nThe \"Release\" solution configuration includes performance optimizations for the best user experience but complicates debugging Dolphin. The \"Debug\" solution configuration is significantly slower, more verbose and less permissive but makes debugging Dolphin easier.\\nBuilding for Linux and macOS\\nDolphin requires CMake for systems other than Windows. You need a recent version of GCC or Clang with decent c++20 support. CMake will inform you if your compiler is too old. Many libraries are bundled with Dolphin and used if they\\'re not installed on your system. CMake will inform you if a bundled library is used or if you need to install any missing packages yourself. You may refer to the wiki for more information.\\nMake sure to pull submodules before building:\\ngit submodule update --init\\nmacOS Build Steps:\\nA binary supporting a single architecture can be built using the following steps:\\nmkdir build\\ncd build\\ncmake ..\\nmake -j $(sysctl -n hw.logicalcpu)\\nAn application bundle will be created in ./Binaries.\\nA script is also provided to build universal binaries supporting both x64 and ARM in the same application bundle using the following steps:\\nmkdir build\\ncd build\\npython ../BuildMacOSUniversalBinary.py\\nUniversal binaries will be available in the universal folder\\nDoing this is more complex as it requires installation of library dependencies for both x64 and ARM (or universal library equivalents) and may require specifying additional arguments to point to relevant library locations. Execute BuildMacOSUniversalBinary.py --help for more details.\\nLinux Global Build Steps:\\nTo install to your system.\\nmkdir build\\ncd build\\ncmake ..\\nmake -j $(nproc)\\nsudo make install\\nLinux Local Build Steps:\\nUseful for development as root access is not required.\\nmkdir Build\\ncd Build\\ncmake .. -DLINUX_LOCAL_DEV=true\\nmake -j $(nproc)\\nln -s ../../Data/Sys Binaries/\\nLinux Portable Build Steps:\\nCan be stored on external storage and used on different Linux systems. Or useful for having multiple distinct Dolphin setups for testing/development/TAS.\\nmkdir Build\\ncd Build\\ncmake .. -DLINUX_LOCAL_DEV=true\\nmake -j $(nproc)\\ncp -r ../Data/Sys/ Binaries/\\ntouch Binaries/portable.txt\\nBuilding for Android\\nThese instructions assume familiarity with Android development. If you do not have an Android dev environment set up, see AndroidSetup.md.\\nMake sure to pull submodules before building:\\ngit submodule update --init\\nIf using Android Studio, import the Gradle project located in ./Source/Android.\\nAndroid apps are compiled using a build system called Gradle. Dolphin\\'s native component, however, is compiled using CMake. The Gradle script will attempt to run a CMake build automatically while building the Java code.\\nUninstalling\\nOn Windows, simply remove the extracted directory, unless it was installed with the NSIS installer, in which case you can uninstall Dolphin like any other Windows application.\\nLinux users can run cat install_manifest.txt | xargs -d \\'\\\\n\\' rm as root from the build directory to uninstall Dolphin from their system.\\nmacOS users can simply delete Dolphin.app to uninstall it.\\nAdditionally, you\\'ll want to remove the global user directory if you don\\'t plan on reinstalling Dolphin.\\nCommand Line Usage\\nUsage: Dolphin.exe [options]... [FILE]...\\n\\nOptions:\\n  --version             show program\\'s version number and exit\\n  -h, --help            show this help message and exit\\n  -u USER, --user=USER  User folder path\\n  -m MOVIE, --movie=MOVIE\\n                        Play a movie file\\n  -e <file>, --exec=<file>\\n                        Load the specified file\\n  -n <16-character ASCII title ID>, --nand_title=<16-character ASCII title ID>\\n                        Launch a NAND title\\n  -C <System>.<Section>.<Key>=<Value>, --config=<System>.<Section>.<Key>=<Value>\\n                        Set a configuration option\\n  -s <file>, --save_state=<file>\\n                        Load the initial save state\\n  -d, --debugger        Show the debugger pane and additional View menu options\\n  -l, --logger          Open the logger\\n  -b, --batch           Run Dolphin without the user interface (Requires\\n                        --exec or --nand-title)\\n  -c, --confirm         Set Confirm on Stop\\n  -v VIDEO_BACKEND, --video_backend=VIDEO_BACKEND\\n                        Specify a video backend\\n  -a AUDIO_EMULATION, --audio_emulation=AUDIO_EMULATION\\n                        Choose audio emulation from [HLE|LLE]\\nAvailable DSP emulation engines are HLE (High Level Emulation) and LLE (Low Level Emulation). HLE is faster but less accurate whereas LLE is slower but close to perfect. Note that LLE has two submodes (Interpreter and Recompiler) but they cannot be selected from the command line.\\nAvailable video backends are \"D3D\" and \"D3D12\" (they are only available on Windows), \"OGL\", and \"Vulkan\". There\\'s also \"Null\", which will not render anything, and \"Software Renderer\", which uses the CPU for rendering and is intended for debugging purposes only.\\nDolphinTool Usage\\nusage: dolphin-tool COMMAND -h\\n\\ncommands supported: [convert, verify, header]\\nUsage: convert [options]... [FILE]...\\n\\nOptions:\\n  -h, --help            show this help message and exit\\n  -u USER, --user=USER  User folder path, required for temporary processing\\n                        files.Will be automatically created if this option is\\n                        not set.\\n  -i FILE, --input=FILE\\n                        Path to disc image FILE.\\n  -o FILE, --output=FILE\\n                        Path to the destination FILE.\\n  -f FORMAT, --format=FORMAT\\n                        Container format to use. Default is RVZ. [iso|gcz|wia|rvz]\\n  -s, --scrub           Scrub junk data as part of conversion.\\n  -b BLOCK_SIZE, --block_size=BLOCK_SIZE\\n                        Block size for GCZ/WIA/RVZ formats, as an integer.\\n                        Suggested value for RVZ: 131072 (128 KiB)\\n  -c COMPRESSION, --compression=COMPRESSION\\n                        Compression method to use when converting to WIA/RVZ.\\n                        Suggested value for RVZ: zstd [none|zstd|bzip|lzma|lzma2]\\n  -l COMPRESSION_LEVEL, --compression_level=COMPRESSION_LEVEL\\n                        Level of compression for the selected method. Ignored\\n                        if \\'none\\'. Suggested value for zstd: 5\\nUsage: verify [options]...\\n\\nOptions:\\n  -h, --help            show this help message and exit\\n  -u USER, --user=USER  User folder path, required for temporary processing\\n                        files.Will be automatically created if this option is\\n                        not set.\\n  -i FILE, --input=FILE\\n                        Path to disc image FILE.\\n  -a ALGORITHM, --algorithm=ALGORITHM\\n                        Optional. Compute and print the digest using the\\n                        selected algorithm, then exit. [crc32|md5|sha1]\\nUsage: header [options]...\\n\\nOptions:\\n  -h, --help            show this help message and exit\\n  -i FILE, --input=FILE\\n                        Path to disc image FILE.\\n  -b, --block_size      Optional. Print the block size of GCZ/WIA/RVZ formats,\\nthen exit.\\n  -c, --compression     Optional. Print the compression method of GCZ/WIA/RVZ\\n                        formats, then exit.\\n  -l, --compression_level\\n                        Optional. Print the level of compression for WIA/RVZ\\n                        formats, then exit.',\n",
       " 'Windows XP Keygen!\\nFAQ\\nWhat does it do?\\nThis program allows you to generate endless Windows XP keys. You also can use it to check your already existing keys.\\nHow does it work?\\nThis program is based on this paper Basically, it uses a cracked private key from Microsoft to sign some stuff encoded in the 25-digit product key. It also does this process in reverse to check for the validation of the keys.\\nHow do I use it?\\nIt all comes down to four simple steps:\\n1. Use this program to generate a key, and use such key during installation.\\n2. After installation, you will be prompted to activate Windows. Select the telephone activation method, then, fire up xp_activate32.exe and enter the installation ID that the activation wizard gave you.\\n3. Click \"Next\"\\n4. Profit!\\nREQUIREMENTS:\\nOpenSSL >0.9.8b',\n",
       " \"Leetcode solutions for 🚀 NeetCode.io\\nThis repo hosts the solutions found on NeetCode.io including the solutions shown on the NeetCode YouTube channel. The site will periodically be updated with new solutions from this repo!\\n\\nSolutions from these languages will be linked from NeetCode.io:\\nPython, Java, JavaScript, C++, Go, Swift, C#, TypeScript, Rust, Kotlin, Ruby, C, Scala and Dart\\nSolutions are also welcome for any other supported language on leetcode.com!\\nContributing\\nPlease read the contributing guidlines before opening a PR\\nTo contribute, please fork this repo and open a PR adding a missing solution from the supported languages.\\nIf you would like to have collaborator permissions on the repo to merge your own PRs or review others' PRs please let me know.\\nCredits\\nMissing Solutions\\nArrays & Hashing\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0217 - Contains Duplicate\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0242 - Valid Anagram\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n1299 - Replace Elements With Greatest Element On Right Side\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0392 - Is Subsequence\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0058 - Length of Last Word\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0001 - Two Sum\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0014 - Longest Common Prefix\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0049 - Group Anagrams\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0118 - Pascals Triangle\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0027 - Remove Element\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0929 - Unique Email Addresses\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0205 - Isomorphic Strings\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0605 - Can Place Flowers\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0169 - Majority Element\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0496 - Next Greater Element I\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0724 - Find Pivot Index\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0303 - Range Sum Query - Immutable\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0448 - Find All Numbers Disappeared In An Array\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1189 - Maximum Number of Balloons\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0290 - Word Pattern\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0706 - Design HashMap\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n0347 - Top K Frequent Elements\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0706 - Design Hashmap\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n0238 - Product of Array Except Self\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0036 - Valid Sudoku\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0271 - Encode And Decode Strings\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0128 - Longest Consecutive Sequence\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0075 - Sort Colors\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0535 - Encode And Decode Tinyurl\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0554 - Brick Wall\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0122 - Best Time to Buy And Sell Stock II\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n0560 - Subarray Sum Equals K\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1930 - Unique Length 3 Palindromic Subsequences\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1963 - Minimum Number of Swaps to Make The String Balanced\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n2001 - Number of Pairs of Interchangeable Rectangles\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n2002 - Maximum Product of The Length of Two Palindromic Subsequences\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n2017 - Grid Game\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0438 - Find All Anagrams In a String\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0028 - Find The Index of The First Occurrence In a String\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0280 - Wiggle Sort\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0179 - Largest Number\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0523 - Continuous Subarray Sum\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0838 - Push Dominoes\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0187 - Repeated Dna Sequences\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0380 - Insert Delete Get Random O(1)\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n1461 - Check if a String Contains All Binary Codes of Size K\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0304 - Range Sum Query 2D Immutable\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0665 - Non Decreasing Array\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n0041 - First Missing Positive\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\nTwo Pointers\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0125 - Valid Palindrome\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0680 - Valid Palindrome II\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1984 - Minimum Difference Between Highest And Lowest of K Scores\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0344 - Reverse String\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0088 - Merge Sorted Array\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0283 - Move Zeroes\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0026 - Remove Duplicates From Sorted Array\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0167 - Two Sum II Input Array Is Sorted\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0015 - 3Sum\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0018 - 4Sum\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0011 - Container With Most Water\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n1498 - Number of Subsequences That Satisfy The Given Sum Condition\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0189 - Rotate Array\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n1968 - Array With Elements Not Equal to Average of Neighbors\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0881 - Boats to Save People\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0042 - Trapping Rain Water\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\nSliding Window\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0121 - Best Time to Buy And Sell Stock\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0219 - Contains Duplicate II\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1343 - Number of Sub Arrays of Size K and Avg Greater than or Equal to Threshold\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0003 - Longest Substring Without Repeating Characters\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0424 - Longest Repeating Character Replacement\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0567 - Permutation In String\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1838 - Frequency of The Most Frequent Element\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1888 - Minimum Number of Flips to Make The Binary String Alternating\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0209 - Minimum Size Subarray Sum\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0658 - Find K Closest Elements\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0076 - Minimum Window Substring\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0239 - Sliding Window Maximum\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\nStack\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0020 - Valid Parentheses\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0682 - Baseball Game\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0225 - Implement Stack Using Queues\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0155 - Min Stack\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0150 - Evaluate Reverse Polish Notation\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0022 - Generate Parentheses\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0735 - Asteroid Collision\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0739 - Daily Temperatures\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0901 - Online Stock Span\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0853 - Car Fleet\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0071 - Simplify Path\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0394 - Decode String\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n0402 - Remove K Digits\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n1209 - Remove All Adjacent Duplicates In String II\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0132 - 132 Pattern\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0895 - Maximum Frequency Stack\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0084 - Largest Rectangle In Histogram\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\nBinary Search\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0704 - Binary Search\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0035 - Search Insert Position\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0374 - Guess Number Higher Or Lower\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n0441 - Arranging Coins\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0977 - Squares of a Sorted Array\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0367 - Valid Perfect Square\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n0074 - Search a 2D Matrix\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0875 - Koko Eating Bananas\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0033 - Search In Rotated Sorted Array\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n0153 - Find Minimum In Rotated Sorted Array\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0981 - Time Based Key Value Store\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0034 - Find First And Last Position of Element In Sorted Array\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n1898 - Maximum Number of Removable Characters\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0116 - Populating Next Right Pointers In Each Node\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1268 - Search Suggestions System\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0410 - Split Array Largest Sum\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0004 - Median of Two Sorted Arrays\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\nLinked List\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0206 - Reverse Linked List\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0021 - Merge Two Sorted Lists\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0234 - Palindrome Linked List\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0203 - Remove Linked List Elements\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0083 - Remove Duplicates From Sorted List\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0876 - Middle of the Linked List\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0160 - Intersection of Two Linked Lists\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0143 - Reorder List\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0019 - Remove Nth Node From End of List\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n0138 - Copy List With Random Pointer\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0707 - Design Linked List\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1472 - Design Browser History\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0002 - Add Two Numbers\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n0141 - Linked List Cycle\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n0287 - Find The Duplicate Number\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0024 - Swap Nodes In Pairs\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0148 - Sort List\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0086 - Partition List\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0061 - Rotate List\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0092 - Reverse Linked List II\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0622 - Design Circular Queue\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0147 - Insertion Sort List\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0146 - LRU Cache\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n0023 - Merge K Sorted Lists\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0025 - Reverse Nodes In K Group\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\nTrees\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0094 - Binary Tree Inorder Traversal\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0226 - Invert Binary Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0104 - Maximum Depth of Binary Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0543 - Diameter of Binary Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0110 - Balanced Binary Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0100 - Same Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0572 - Subtree of Another Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n0108 - Convert Sorted Array to Binary Search Tree\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0617 - Merge Two Binary Trees\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0112 - Path Sum\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n0606 - Construct String From Binary Tree\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0235 - Lowest Common Ancestor of a Binary Search Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n0701 - Insert into a Binary Search Tree\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0450 - Delete Node in a BST\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0102 - Binary Tree Level Order Traversal\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0199 - Binary Tree Right Side View\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n1448 - Count Good Nodes In Binary Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0098 - Validate Binary Search Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0230 - Kth Smallest Element In a Bst\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n0105 - Construct Binary Tree From Preorder And Inorder Traversal\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0096 - Unique Binary Search Trees\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0129 - Sum Root to Leaf Numbers\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0337 - House Robber III\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0951 - Flip Equivalent Binary Trees\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1993 - Operations On Tree\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0894 - All Possible Full Binary Trees\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0513 - Find Bottom Left Tree Value\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0669 - Trim a Binary Search Tree\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0173 - Binary Search Tree Iterator\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0538 - Convert Bst to Greater Tree\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0124 - Binary Tree Maximum Path Sum\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n0297 - Serialize And Deserialize Binary Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\nTries\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0208 - Implement Trie Prefix Tree\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0211 - Design Add And Search Words Data Structure\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n0212 - Word Search II\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\nHeap / Priority Queue\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0703 - Kth Largest Element In a Stream\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n1046 - Last Stone Weight\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0973 - K Closest Points to Origin\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n0215 - Kth Largest Element In An Array\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n0621 - Task Scheduler\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0355 - Design Twitter\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1834 - Single Threaded Cpu\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n1845 - Seat Reservation Manager\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1882 - Process Tasks Using Servers\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1985 - Find The Kth Largest Integer In The Array\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n0767 - Reorganize String\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1405 - Longest Happy String\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1094 - Car Pooling\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0295 - Find Median From Data Stream\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1383 - Maximum Performance of a Team\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\nBacktracking\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0078 - Subsets\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0039 - Combination Sum\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0077 - Combinations\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0046 - Permutations\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0090 - Subsets II\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0040 - Combination Sum II\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n0047 - Permutations II\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0079 - Word Search\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n0131 - Palindrome Partitioning\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0093 - Restore Ip Addresses\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0017 - Letter Combinations of a Phone Number\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n0473 - Matchsticks to Square\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1849 - Splitting a String Into Descending Consecutive Values\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1980 - Find Unique Binary String\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1239 - Maximum Length of a Concatenated String With Unique Characters\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0698 - Partition to K Equal Sum Subsets\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0051 - N Queens\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0052 - N Queens II\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\nGraphs\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0463 - Island Perimeter\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0953 - Verifying An Alien Dictionary\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n0200 - Number of Islands\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0133 - Clone Graph\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0695 - Max Area of Island\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n1905 - Count Sub Islands\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0417 - Pacific Atlantic Water Flow\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0130 - Surrounded Regions\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n1466 - Reorder Routes to Make All Paths Lead to The City Zero\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0994 - Rotting Oranges\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0286 - Walls And Gates\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0909 - Snakes And Ladders\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0752 - Open The Lock\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0802 - Find Eventual Safe States\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0207 - Course Schedule\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n0210 - Course Schedule II\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n1958 - Check if Move Is Legal\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0934 - Shortest Bridge\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1091 - Shortest Path in Binary Matrix\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0684 - Redundant Connection\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0323 - Number of Connected Components In An Undirected Graph\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n0261 - Graph Valid Tree\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n1553 - Minimum Number of Days to Eat N Oranges\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0127 - Word Ladder\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\nAdvanced Graphs\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0332 - Reconstruct Itinerary\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1584 - Min Cost to Connect All Points\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n0743 - Network Delay Time\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1514 - Path With Maximum Probability\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0778 - Swim In Rising Water\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0269 - Alien Dictionary\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0787 - Cheapest Flights Within K Stops\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n1-D Dynamic Programming\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0070 - Climbing Stairs\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0746 - Min Cost Climbing Stairs\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0198 - House Robber\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0213 - House Robber II\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0005 - Longest Palindromic Substring\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0647 - Palindromic Substrings\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0091 - Decode Ways\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n0322 - Coin Change\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n0152 - Maximum Product Subarray\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0139 - Word Break\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0300 - Longest Increasing Subsequence\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0416 - Partition Equal Subset Sum\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0120 - Triangle\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0740 - Delete And Earn\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0256 - Paint House\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0377 - Combination Sum IV\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0279 - Perfect Squares\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1856 - Maximum Subarray Min Product\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0983 - Minimum Cost For Tickets\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0343 - Integer Break\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0673 - Number of Longest Increasing Subsequence\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0691 - Stickers to Spell Word\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n2-D Dynamic Programming\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0062 - Unique Paths\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0063 - Unique Paths II\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n1143 - Longest Common Subsequence\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0309 - Best Time to Buy And Sell Stock With Cooldown\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0518 - Coin Change II\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0494 - Target Sum\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0097 - Interleaving String\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n0877 - Stone Game\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0064 - Minimum Path Sum\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0329 - Longest Increasing Path In a Matrix\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0221 - Maximal Square\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n5782 - Maximum Alternating Subsequence Sum\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0115 - Distinct Subsequences\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n0072 - Edit Distance\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n1220 - Count Vowels Permutation\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0312 - Burst Balloons\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n1866 - Number of Ways to Rearrange Sticks With K Sticks Visible\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0010 - Regular Expression Matching\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\nGreedy\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0053 - Maximum Subarray\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0918 - Maximum Sum Circular Subarray\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0055 - Jump Game\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0045 - Jump Game II\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n1871 - Jump Game VII\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0134 - Gas Station\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0846 - Hand of Straights\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n1423 - Maximum Points You Can Obtain From Cards\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1899 - Merge Triplets to Form Target Triplet\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0763 - Partition Labels\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n0678 - Valid Parenthesis String\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n✔️\\n1921 - Eliminate Maximum Number of Monsters\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1029 - Two City Scheduling\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\nIntervals\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0057 - Insert Interval\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0056 - Merge Intervals\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n0435 - Non Overlapping Intervals\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n0252 - Meeting Rooms\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0253 - Meeting Rooms II\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n1288 - Remove Covered Intervals\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n1851 - Minimum Interval to Include Each Query\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\nMath & Geometry\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0048 - Rotate Image\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0054 - Spiral Matrix\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n0073 - Set Matrix Zeroes\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n0202 - Happy Number\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0066 - Plus One\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0009 - Palindrome Number\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n0263 - Ugly Number\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n1260 - Shift 2D Grid\\n❌\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n0013 - Roman to Integer\\n❌\\n❌\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0012 - Integer to Roman\\n❌\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n0050 - Pow(x, n)\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n0043 - Multiply Strings\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n2013 - Detect Squares\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n1041 - Robot Bounded In Circle\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n0006 - Zigzag Conversion\\n❌\\n✔️\\n❌\\n❌\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n2028 - Find Missing Observations\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\n❌\\nBit Manipulation\\nProblem C C++ C# Dart GO Java JS Kotlin Python Ruby Rust Scala Swift TS\\n0136 - Single Number\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0191 - Number of 1 Bits\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0338 - Counting Bits\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0190 - Reverse Bits\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0268 - Missing Number\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0371 - Sum of Two Integers\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n0007 - Reverse Integer\\n✔️\\n✔️\\n✔️\\n❌\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n✔️\\n0067 - Add Binary\\n✔️\\n✔️\\n❌\\n❌\\n❌\\n✔️\\n❌\\n✔️\\n✔️\\n❌\\n✔️\\n❌\\n❌\\n❌\\nNeed to update the README? Update the template instead.\",\n",
       " \"SpringChallenge2023\\nSource code for CodinGame's Spring Challenge 2023 event.\\nhttps://www.codingame.com/contests/spring-challenge-2023\\nCommunity starter AIs are located here:\\nhttps://github.com/CodinGame/SpringChallenge2023/tree/main/starterAIs\",\n",
       " '[中文文档]\\nThe project is still under construction, we will continue to update it and welcome contributions/pull requests from the community.\\n| |\\n🤖💬 InternGPT [Paper]\\nInternGPT(short for iGPT) / InternChat(short for iChat) is pointing-language-driven visual interactive system, allowing you to interact with ChatGPT by clicking, dragging and drawing using a pointing device. The name InternGPT stands for interaction, nonverbal, and ChatGPT. Different from existing interactive systems that rely on pure language, by incorporating pointing instructions, iGPT significantly improves the efficiency of communication between users and chatbots, as well as the accuracy of chatbots in vision-centric tasks, especially in complicated visual scenarios. Additionally, in iGPT, an auxiliary control mechanism is used to improve the control capability of LLM, and a large vision-language model termed Husky is fine-tuned for high-quality multi-modal dialogue (impressing ChatGPT-3.5-turbo with 93.89% GPT-4 Quality).\\n🥳 🚀 What\\'s New\\n(2023.05.24) 🎉🎉🎉 We have supported the DragGAN! Please see the video demo for the usage. Let\\'s try this awesome feauture: Demo. （我们现在支持了功能完全的DragGAN! 可以拖动、可以自定义图片，具体用法见video demo，复现的DragGAN代码在这里，在线demo在这里）\\n(2023.05.18) We have supported ImageBind. Please see the video demo for the usage.\\n(2023.05.15) The model_zoo including HuskyVQA has been released! Try it on your local machine!\\n(2023.05.15) Our code is also publicly available on Hugging Face! You can duplicate the repository and run it on your own GPUs.\\n🤖💬 Online Demo\\nInternGPT is online (see https://igpt.opengvlab.com). Let\\'s try it!\\n[NOTE] It is possible that you are waiting in a lengthy queue. You can clone our repo and run it with your private GPU.\\n🧭 User Manual\\nUpdate:\\n(2023.05.24) We now support DragGAN. You can try it as follows:\\nClick the button New Image;\\nClick the image where blue denotes the start point and red denotes the end point;\\nNotice that the number of blue points is the same as the number of red points. Then you can click the button Drag It;\\nAfter processing, you will receive an edited image and a video that visualizes the editing process.\\n\\n(2023.05.18) We now support ImageBind. If you want to generate a new image conditioned on audio, you can upload an audio file in advance:\\nTo generate a new image from a single audio file, you can send the message like: \"generate a real image from this audio\";\\nTo generate a new image from audio and text, you can send the message like: \"generate a real image from this audio and {your prompt}\";\\nTo generate a new image from audio and image, you need to upload an image and then send the message like: \"generate a new image from above image and audio\".\\n\\nMain features:\\nAfter uploading the image, you can have a multi-modal dialogue by sending messages like: \"what is it in the image?\" or \"what is the background color of image?\".\\nYou also can interactively operate, edit or generate the image as follows:\\nYou can click the image and press the button Pick to visualize the segmented region or press the button OCR to recognize the words at chosen position;\\nTo remove the masked reigon in the image, you can send the message like: \"remove the masked region\";\\nTo replace the masked reigon in the image, you can send the message like: \"replace the masked region with {your prompt}\";\\nTo generate a new image, you can send the message like: \"generate a new image based on its segmentation describing {your prompt}\"\\nTo create a new image by your scribble, you should press button Whiteboard and draw in the board. After drawing, you need to press the button Save and send the message like: \"generate a new image based on this scribble describing {your prompt}\".\\nVideo Demo with DragGAN:\\ndragGAN_demo2.mp4\\nVideo Demo with ImageBind:\\nvideo_demo_with_imagebind.mp4\\niGPT Video Demo:\\nonline_demo.mp4\\n🗓️ Schedule\\nSupport VisionLLM\\nSupport Chinese\\nSupport MOSS\\nMore powerful foundation models based on InternImage and InternVideo\\nMore accurate interactive experience\\nOpenMMLab toolkit\\nWeb page & code generation\\nSupport search engine\\nLow cost deployment\\nSupport DragGAN\\nSupport ImageBind\\nResponse verification for agent\\nPrompt optimization\\nUser manual and video demo\\nSupport voice assistant\\nSupport click interaction\\nInteractive image editing\\nInteractive image generation\\nInteractive visual question answering\\nSegment anything\\nImage inpainting\\nImage caption\\nImage matting\\nOptical character recognition\\nAction recognition\\nVideo caption\\nVideo dense caption\\nVideo highlight interpretation\\n🏠 System Overview\\n🎁 Major Features\\nRemove the masked object\\nInteractive image editing\\nImage generation\\nInteractive visual question answer\\nInteractive image generation\\nVideo highlight interpretation\\n🛠️ Installation\\nSee INSTALL.md\\n👨\\u200d🏫 Get Started\\nRunning the following shell can start a gradio service:\\npython -u app.py --load \"HuskyVQA_cuda:0,SegmentAnything_cuda:0,ImageOCRRecognition_cuda:0\" --port 3456\\nif you want to enable the voice assistant, please use openssl to generate the certificate:\\nmkdir certificate\\nopenssl req -x509 -newkey rsa:4096 -keyout certificate/key.pem -out certificate/cert.pem -sha256 -days 365 -nodes\\nand then run:\\npython -u app.py --load \"HuskyVQA_cuda:0,SegmentAnything_cuda:0,ImageOCRRecognition_cuda:0\" --port 3456 --https\\n🎫 License\\nThis project is released under the Apache 2.0 license.\\n🖊️ Citation\\nIf you find this project useful in your research, please consider cite:\\n@article{2023interngpt,\\n  title={InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language},\\n  author={Liu, Zhaoyang and He, Yinan and Wang, Wenhai and Wang, Weiyun and Wang, Yi and Chen, Shoufa and Zhang, Qinglong and Yang, Yang and Li, Qingyun and Yu, Jiashuo and others},\\n  journal={arXiv preprint arXiv:2305.05662},\\n  year={2023}\\n}\\n🤝 Acknowledgement\\nThanks to the open source of the following projects:\\nHugging Face \\u2002 LangChain \\u2002 TaskMatrix \\u2002 SAM \\u2002 Stable Diffusion \\u2002 ControlNet \\u2002 InstructPix2Pix \\u2002 BLIP \\u2002 Latent Diffusion Models \\u2002 EasyOCR\\u2002 ImageBind \\u2002 DragGAN\\nWelcome to discuss with us and continuously improve the user experience of InternGPT.\\nWeChat QR Code:',\n",
       " '中文文档 English README\\n\\n项目简介\\n喜欢这个插件的小伙伴，可以给我的GITHUB项目 KeepChatGPT 点个⭐️STAR支持一下。\\n这是一款开源的、免费的、高效的ChatGPT畅聊插件，它可以让你的聊天无比丝滑，一劳永逸摆脱各种报错和警告，省去足足10个多余步骤，释放双手不再刷新网页，并且作者还在持续更新更多的增强功能，包括取消审计、克隆对话、净化页面、展示大屏、展示全屏、言无不尽、拦截跟踪、日新月异等等。\\n没有研发经费，纯用爱发电，欢迎关注。谢谢赞赏猫粮\\n展示\\nPC端，亮色主题，享受免费的KeepChatGPT畅聊用户专属金标，它代表着你的AI体验发生了骤变：\\nPC端，暗色主题+展示大屏：\\nPC端，暗色主题+展示全屏：\\n移动端：\\n功能简介\\n解决了报错：NetworkError when attempting to fetch resource.\\n解决了报错：Something went wrong. If this issue persists please contact us through our help center at help.openai.com.\\n解决了报错：Conversation not found\\n解决了报错：This content may violate our content policy. If you believe this to be in error, please submit your feedback — your input will aid our research in this area.\\n解决了聊天中断\\n解决了频繁刷新\\n支持多国语言\\n解决了对话里的用户名会被手误复制的官方BUG\\n支持自由地取消后台监管审计\\n支持移动端(鸿蒙、Android、iOS)\\n支持自由地调整时间间隔\\n支持便捷地克隆并且无损地编辑指定对话\\n支持净化页面\\n支持展示大屏\\n支持展示全屏\\n支持言无不尽\\n支持拦截跟踪\\n支持日新月异\\n以上是功能简介，功能详细介绍在本文底部\\n并且本文底部的其他说明，作者浅析了为何会出现大规模地网络错误、常见错误信息解决方案\\n序号 使用KeepChatGPT插件以后再也不会出现以下场面\\n1\\n2\\n3\\n4\\n用户反馈\\n有好有坏\\n对于好的谢谢大家点赞\\n对于坏的会持续更新\\n对比\\n实验环境 不使用KeepChatGPT插件 使用KeepChatGPT插件\\n现象 聊天频频红框警告NetworkError，\\n每隔十几分钟出现一次，必须刷新网页。 再也不会出现网络报错，\\n再也不用刷新网页。\\n步骤1 下发指令 下发指令\\n步骤2 等待结果 等待结果\\n步骤3 遇到网络报错 得到结果\\n步骤4 尝试点击重新下发\\n步骤5 再次遇到网络报错\\n步骤6 复制刚刚的指令\\n步骤7 刷新页面\\n步骤8 等待网页加载完\\n步骤9 打开刚刚的聊天会话\\n步骤10 粘贴刚刚的指令\\n步骤11 再次下发指令\\n步骤12 再次等待结果\\n步骤13 得到结果\\n通过对比可知，足足省去10个多余的步骤，顺畅地聊天\\n原理\\n利用Headless绕过打开页面时的Cloudflare爬虫验证\\n利用non-click绕过不定时的Cloudflare机器人验证\\n保持流量最小化原则\\n鼠标移到专属金标选择显示调试可以查阅绕过过程\\n用法 电脑系统\\n浏览器首选Chrome、Firefox、Edge，其他主流浏览器都是主动兼容这3个浏览器的；\\n安装Tampermonkey浏览器拓展，可以从 Tampermonkey官网 安装；\\n安装KeepChatGPT插件，可以从 安装渠道 选一个渠道安装；\\n打开 ChatGPT 尽情享用吧；\\n另外，还有一个更巧妙的方法就是问ChatGPT：如何安装tampermonkey拓展和greasyfork上的插件\\n用法 鸿蒙系统\\n浏览器首选Firefox；\\n安装Firefox浏览器App，可以从 华为应用市场、Firefox官网 安装；\\n打开Firefox浏览器App > 右下角... > 附加组件 > 附加组件管理器 > Tampermonkey右边的+；\\n安装KeepChatGPT插件，可以从 安装渠道 选一个渠道安装；\\n用法 苹果系统\\n浏览器首选Safari，其他浏览器受限于苹果的政策少有支持JS插件的；\\n安装Stay浏览器拓展App，可以从 App Store 安装；\\n使用说明参考Stay官网；\\n安装KeepChatGPT插件，可以从 安装渠道 选一个渠道安装；\\n安装渠道\\n序号 UserScript源\\n1 Github\\n2 GreasyFork\\n作者只提供插件的安装方式，官方来源只有以上两个，请认准官方来源。\\n作者觉得插件比拓展好，大家随时可以审计安全性，有没有偷偷上传数据大家都可以随时发现。\\n⚠️谷歌应用商店 和 ⚠️微软应用商店 上的同名拓展不是作者提供的，并且抄袭本项目，居然还向用户收费。\\n其他说明\\n关于 为何会出现大规模地网络错误\\n全球已出现算力荒，openai同样存在。\\nopenai大火，用户量、用户在线时长、用户使用频率同时激增，导致加剧资源紧张。\\n衍生出大量AI产品、AI机器人，都在私下调用ChatGPT的API和网页版ChatGPT，甚至调用频率远超所有真实用户的总和。\\nopenai接入Cloudflare，开启强力保护规则，拦截私下接入openai的AI产品、AI机器人。\\n就像图形验证码一样，本意是拦截机器人，可是一旦出现验证码被识别的风险，网站管理员就会把图形验证码开发得更复杂，影响了真实用户，但又确实拦截了机器人。\\nCloudflare是公共服务，它服务于所有网站，它的保护规则和风控策略是通用的。很多不希望被爬虫、被机器人访问、被黑客攻击、被大流量访问的网站都会接入Cloudflare，所以Cloudflare有丰富的风控策略。\\n大量国外用户是家庭网络，Cloudflare判断他们的网络没有风险，所以他们几乎没报错。\\n大量国内用户使用各种位移魔法(下面简称666)，然而很多666的ip曾经或者正在被Cloudflare列入了强力保护规则的重点关照名单里。不一定是用户本人导致的，可能是前人乘凉 后人遭殃，也可能是同C段的很多ip此时此刻还在频繁地触发风控，也可能用户本人都不知道自己使用的是共享666，触发了风控，Cloudflare判断他们的网络存在风险，于是出现报错，需要验证真实用户。\\n原因不仅限以上内容，这里仅仅是抛砖引玉。\\n关于 使用了本插件依然出现网络错误 的原因和解决方案\\n原因: 参考 关于 调整间隔 功能。解决方案: 适度调整keep的间隔。\\n原因: 参考 关于 为何会出现大规模地网络错误。解决方案: 更换666的ip、机房、运营商、渠道，一个人的666才是最香的。\\n关于 错误信息429 - Too many requests in 1 hour. Try again later 的原因和解决方案\\n首先，429错误有好多种，先确认是不是 关于 其他错误 的原因和解决方案 里的429错误。如果不是，那以下几种可能:\\n原因: 新注册或者同一手机注册的用户，openai不赠送免费额度，查询链接 openai官网 额度页面，解决方案: 换邮箱和手机号注册。\\n原因: 用完了额度，查询链接 openai官网 额度页面，解决方案: 充值变强。\\n原因: Cloudflare的bug，解决方案: 使用浏览器的隐私模式等chatgpt，如果发现隐私模式能正常使用，就清理浏览器正常模式的openai.com主域名和子域名的所有cookie和本地存储。\\n原因: 可能连你都不知道自己使用的是共享666，你有一群相同ip出口的网上邻居，他们一直在以各种目的频繁请求，虽然他们的访问量很大但是他们一直控制在临界点不触发429错误，而你使用了本插件以后把他们拖下水了，所以在你懵逼为何429的时候你的网上邻居们也在懵逼为何突然429，解决方案: 更换666的ip、机房、运营商、渠道，一个人的666才是最香的。\\n关于 取消审计 功能\\n默认情况下，你所有的对话都会被openai官方自动化审计，如果openai审计发现你有过多的违规、违反 openai政策 的对话，你的账号就存在被限制甚至被封号的风险。\\n通过勾选本插件的取消审计功能加上你巧妙的提示词，可以最大程度地免受影响。\\n关于 调整间隔 功能\\n那个值指的是keep(保活)的时间间隔，单位是秒。\\n时间间隔越大，keep的速度就越慢，对网站的影响就越小，你的账号就越安全。\\n时间间隔越小，keep的速度就越快，你的网络错误就越不会出现。\\n建议间隔30秒以上。\\n作者平时设置的是150秒。\\n关于 克隆对话 功能\\nChatGPT属于AI提示工程。\\n提示工程做的最多的一件事就是反复调整提示词，直到发现机器人真正理解了，并且结果满足你的要求。\\n在对结果满意之前，反复的调整提示词里做的最多的一件事就是复制粘贴自己发过的内容。\\n勾选了克隆对话以后，可以通过点击想要重新优化的对话前面的头像，对话框就会立刻出现。\\n实验环境 不勾选克隆对话 勾选克隆对话\\n步骤1 下发指令 下发指令\\n步骤2 得到结果 得到结果\\n步骤3 对结果不满意 对结果不满意\\n步骤4 鼠标点击指令的开头不放 点击对话头像\\n步骤5 鼠标滚轮滚动 开始调整指令\\n步骤6 鼠标拖拉到指令的结尾\\n步骤7 复制指令\\n步骤8 鼠标点击对话框\\n步骤9 粘贴指令\\n步骤10 开始调整指令\\n通过对比可知，足足省去5个多余的步骤，顺畅地聊天\\n省去的步骤是成倍的，因为当你觉得调整后的对话还不错，但还不是非常满意，还需要进一步调整的时候，每调整一次，多余的步骤就要做一次，所以勾选克隆对话有利于提升效率。\\n关于 净化页面 功能\\n对于普通用户，常常会看到ChatGPT首页https://chat.openai.com/堆积了满屏的无用的提示词。\\n勾选净化页面以后，可以让首页焕然一新，享受类似PLUS用户的金标，提升体验感。\\n关于 言无不尽 功能\\n顾名思义，就是指一个人在发言时不要停下，尽情地表达，没有遗漏。\\n新版的ChatGPT在回复内容时，若内容很多导致发言时间超过60多秒，则会弹出Continue generating的按钮。\\n使得用户需要反反复复点击继续。\\n勾选了言无不尽以后，用户可以无人值守地享受ChatGPT尽情地表达，直到说完所有内容。\\n经过实际测试，这个功能可以让ChatGPT发言长达5分30秒，大大地突破了原本的60秒限制。并且用户至少省去点击5次Continue generating按钮。\\n实验环境 不勾选言无不尽 勾选言无不尽\\n步骤1 下发指令 下发指令\\n步骤2 等待结果 等待结果\\n步骤3 盯着结果 得到完整结果\\n步骤4 得到不完整结果\\n步骤5 点击Continue\\n步骤6 等待结果\\n步骤7 盯着结果\\n步骤8 得到不完整结果\\n步骤9 点击Continue\\n步骤10~21 重复4次以上动作...\\n步骤22 等待结果\\n步骤23 盯着结果\\n步骤24 得到完整结果\\n通过对比可知，足足省去21个多余的步骤，顺畅地聊天\\n省去的步骤也是成倍的，因为这个功能突破的上限还不止5分30秒，所以勾选言无不尽有利于提升效率。\\n关于 拦截跟踪 功能\\n每次访问ChatGPT网页的时候，都会被OpenAI进行大量的行为分析、用户跟踪、浏览器环境信息上传等，大家可以在控制台的网络选项卡看到。\\n勾选拦截跟踪以后，可以拦截大部分的跟踪行为，保护了用户的隐私。\\n经过实际测试，默认情况下打开ChatGPT页面有产生50至100个网络请求，而勾选这个功能可以使得请求数缩少为只有35个并且ChatGPT完全正常运行。\\n所以，这个功能的另一个惊喜的效果是提高网页加载速度。\\n也就是说每次打开ChatGPT页面至少有15至65个网络请求全都是在跟踪、分析用户，作者认为这些网络请求完全没必要！\\n所以，强烈建议注重隐私安全的用户勾选这个功能。\\n关于 日新月异 功能\\n顾名思义，指随着大家每天都用chatgpt聊天学习，大家的技术和能力每天都在进步，提示词越来越丰富，答案越来越满意，聊天记录开始不舍得删除。\\n随着新建的聊天项目越来越多，用户也难以区分侧边栏的聊天项目。\\n勾选日新月异以后，侧边栏会出现日期和时间，帮助用户快速定位历史的优质的聊天项目。\\n关于 其他错误 的原因和解决方案\\n出现下述错误信息可参考官方的解决方案: openai官方文档 报错代码\\n401 - Invalid Authentication\\n401 - Incorrect API key provided\\n401 - You must be a member of an organization to use the API\\n429 - Rate limit reached for requests\\n429 - You exceeded your current quota, please check your plan and billing details\\n429 - The engine is currently overloaded, please try again later\\n500 - The server had an error while processing your request\\n关于 PLUS用户是不是不会报错\\nPLUS用户和普通用户一样，在劫难逃。\\n赞赏\\n如果你觉得好用！NB！神器！好顺畅！感觉很棒！NICE！\\n如果你希望作者的小猫吃到更好的猫粮、猫罐头\\n如果本项目对你有帮助\\n如果本项目提高了你工作效率\\n如果你希望本项目持续维护，以继续防止openai接下来新的一轮的报错\\n如果你希望本项目持续升级更多的功能\\n创造不易，维护一个项目需要消耗时间、精力、技术，欢迎欣赏与赞赏\\n可在备注里写上你的ID，谢谢\\nFrom Thanks\\n我的猫\\nbuymeacoffee\\n点击图片\\n爱发电\\n(支持微信、支付宝)\\n点击图片或者扫描\\n微信\\n(偶尔失效)',\n",
       " 'Auto-Photoshop-StableDiffusion-Plugin\\nWith Auto-Photoshop-StableDiffusion-Plugin, you can directly use the capabilities of Automatic1111 Stable Diffusion in Photoshop without switching between programs. This allows you to easily use Stable Diffusion AI in a familiar environment. You can edit your Stable Diffusion image with all your favorite tools and save it right in Photoshop.\\nTable of Contents\\nAuto-Photoshop-StableDiffusion-Plugin\\nTable of Contents\\nDemo:\\nSupport Us On Patreon\\nHow to Install\\nMethod 1: One Click Installer\\nMethod 2: The Unzip Method\\nMethod 3: The UXP Method (for Developers/Programmers Only)\\nFAQ and Known Issues\\nWhat Photoshop version do I need to run the plugin?\\nPath Doesn\\'t Exist\\nPlugin Load Failed\\nNo application are connected to the service\\nLoad command failed in App with ID PS and Version X.X.X\\nException in ASGI application / Expecting value: line 1 column 1\\nNo Generations and Plugin Server doesn\\'t send messages. (Remote setup)\\nNo GPU Options\\nStable Horde\\nColab\\nSupport Us On Patreon:\\nBy supporting us on Patreon, you’ll help us continue to develop and improve the Auto-Photoshop-StableDiffusion-Plugin, making it even easier for you to use Stable Diffusion AI in a familiar environment. As a supporter, you’ll have the opportunity to provide feedback and suggestions for future development. Plus, you’ll get early access to new features and tutorials, as well as exclusive art tutorials and tips from a professional artist. We’re passionate about making AI approachable to artists and with your help, we can continue to do just that.\\nAuto-Photoshop-SD Backers and Sponsors:\\n💎 Diamond:\\nRonny Khalil zachary Razvan Matei\\n🥇 Gold:\\nAlex Florin-Alexandru Ilinescu Robin Edwards\\n🥈 Silver:\\nAmith Thomas Olivier Lefebvre xiao yuan Ezra Blake Zenko Frederic Dreuilhe\\n🥉 Copper:\\nSebastian Karbowniczek Arthur Liu Juan Pablo Mendiola\\nHow To Install:\\nUse method 1 or 2 if you are an Artist use method 3 if you are a Developer/Programmer\\nMethod 1: One Click Installer\\nDownload the .ccx file\\nrun the ccx file . that\\'s all. you will be able to use all of stable diffusion modes (txt2img, img2img, inpainting and outpainting), check the tutorials section to master the tool.\\n(optional step) Install the Auto-Photoshop-SD Extension from Automatic1111. the extension will allow you to use the smart masking and image search features\\na) Copy Auto-Photoshop plugin url\\nb) Paste the url in auto1111\\'s extension tab and click install\\nc) Make sure the Auto-Photoshop plugin is listed, then click \"Apply and Restart UI\"\\nMethod 2: The Unzip Method\\nDownload the .zip file\\nUnzip it in a folder with the same name\\nmove the unzipped folder to the Photoshop Plugin folder\\n(optional step) Install the Auto-Photoshop-SD Extension from Automatic1111. the extension will allow you to use the smart masking and image search features\\nMethod 3: The UXP method (Instruction for Developers):\\nFor artists we recommend you use the one click installer. If you are a developer Watch the any of these videos or follow the instruction bellow.\\nFor artists we recommend you use the one click installer\\nFirst time running the plugin (local Automatic1111):\\ndownload the plugin:\\ngit clone https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin.git\\nopen cmd window in the \"Auto-Photoshop-StableDiffusion-Plugin\" directory and then install the dependencies by typing:\\nnpm install\\nbuild the plugin by transpiling typescript to javascript:\\nnpm run watch\\nrun \"start_server.bat\" inside \"Auto-Photoshop-StableDiffusion-Plugin\" directory\\ngo to where you have automatic1111 installed. Edit the \"webui-user.bat\" in automatic1111 change this line\\nset COMMANDLINE_ARGS= \\nto\\nset COMMANDLINE_ARGS= --api\\nthat will allow the plugin to communicate with the automatic1111 project. After saving close the \"webui-user.bat\" file and run it normally.\\nrun photoshop. go to edit -> prefrences -> plugins\\nmake sure you check \"Enable Developer Mode\" checkbox\\ninstall \"Adobe UXP Developer Tool\" from here Installation (adobe.com) this tool will add the plugin into photoshop\\nrun Adobe UXP Developer Tool and click on \"Add Plugin\" button in the top right. Navigate to where you have \"Auto-Photoshop-StableDiffusion-Plugin\" folder and open \"manifest.json\"\\nselect the plugin and click on Actions -> Load Selected that\\'s it.\\nFirst time running the plugin (remote Automatic1111):\\nThe remote webui must also have --api set in COMMANDLINE_ARGS. You can check if api access is enabled by appending \"/docs#\" to the end of the url. If the documentation includes /sdapi/v1/samplers then api access is enabled.\\ndownload the plugin:\\ngit clone https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin.git\\nedit start_server.bat (or start_server.sh if on linux) to point to the remote installation of Automatic1111\\nrun \"start_server.bat\" inside \"Auto-Photoshop-StableDiffusion-Plugin\" directory\\nrun photoshop. go to edit -> prefrences -> plugins\\nmake sure you check \"Enable Developer Mode\" checkbox\\ninstall \"Adobe UXP Developer Tool\" from here Installation (adobe.com) this tool will add the plugin into photoshop\\nrun Adobe UXP Developer Tool and click on \"Add Plugin\" button in the top right. Navigate to where you have \"Auto-Photoshop-StableDiffusion-Plugin\" folder and open \"manifest.json\"\\nselect the plugin and click on Actions -> Load Selected that\\'s it.\\nDemo:\\nFAQ and Known Issues\\nWhat Photoshop version do I need to run the plugin?\\nThe minimum Photoshop version that the plugin supports is Photoshop v24\\nPlugin Load Failed\\nThere are a few issues that can result in this error, please follow the instructions for the corresponding error message in the UDT logs\\nNo application are connected to the service\\nThis error occurs when Photoshop is not started before the plugin is attempted to be loaded. Simply start photoshop then restart UXP and load the plugin\\nException in ASGI application / Expecting value: line 1 column 1\\nThis error occurs due to mismatched expectations between the plugin and the Automatic1111 backend. It can be solved by both updating the version of the Automatic111 backend to the latest verion, and making sure \"Save text information about generation parameters as chunks to png files\" setting is enabled within the UI.\\nNo Generations and Plugin Server doesn\\'t send messages. (Remote setup)\\nThis error occurs when the remote server does not have the api enabled. You can verify this by attempting to go to the URL you access the webui at and appending \"/docs#\" to the end of the url. If you have permissions, make relaunch the remote instance with the \"--api\" flag.\\nNo GPU Options:\\nwe provide two options to use the auto-photoshp plugin without GPU.\\nStable Horde\\nThis is an awesome free crowdsourced distributed cluster of Stable Diffusion workers. If you like this service, consider joining the horde yourself! the horde is enabled completely by the generosity of volunteers so make sure you don\\'t overwhelm the service and help join the cause if you can. read more on their github page\\nColab:\\nwe link to this Colab directly inside plugin find it in the settings tab. you only need to run it. no need to change any of the settings. copy the gradio.live url the colab will generate and paste it into sd url field in the settings tab.',\n",
       " \"Microsoft Activation Scripts (MAS):\\nA Windows and Office activator using HWID / KMS38 / Online KMS activation methods, with a focus on open-source code and fewer antivirus detections.\\nDownload / How to use it?\\nMethod 1 - PowerShell (Recommended)\\nOn Windows 8.1/10/11, right-click on the windows start menu and select PowerShell or Terminal (Not CMD).\\nCopy-paste the below code and press enter\\nirm https://massgrave.dev/get | iex\\nYou will see the activation options, and follow onscreen instructions.\\nThat's all.\\nMethod 2 - Traditional\\nDownload the file from here\\nRight click on the downloaded zip file and extract\\nIn the extracted folder, find the folder named All-In-One-Version\\nRun the file named MAS_AIO.cmd\\nYou will see the activation options, and follow onscreen instructions.\\nThat's all.\\nTo run the scripts in unattended mode, check here\\nLatest Version: 1.8\\nRelease date: 16-Mar-2023\\nTroubleshooting / Help\\nDownload Original Windows & Office\\nHomepage - https://massgrave.dev\\n\\nMade with Love ❤️\",\n",
       " 'Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training\\nThis is an official implementation of the Sophia-G optimizer in the paper https://arxiv.org/abs/2305.14342 and GPT-2 training scripts. The code is based on nanoGPT. Please cite the paper and star this repo if you find Sophia useful. Thanks!\\n@article{liu2023sophia,\\n title={Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training},\\n author={Liu, Hong and Li, Zhiyuan and Hall, David and Liang, Percy and Ma, Tengyu},\\n journal={arXiv preprint arXiv:2305.14342},\\n year={2023}\\n}\\nNews and Updates\\n🔥 🔥 Training script released for GPT2 Medium (355M).\\n🔥 Watch Sophia running on GPT2 Small (125M) in the wandb report.\\nWe will spend more resources on scaling up to larger models. Please feel free to let us know if you have any feedback or interesting findings from using Sophia.\\nFor Large (770M), please see the hyperparameters we used to produce the results in the paper below in the hyperparameter tuning. The scripts will be released soon (potentially with an improved choice of hyperparameters that we are currently experimenting with.)\\nThe JAX version of Sophia-H will be included at levanter, which is also an amazing code base for language model pre-training.\\nDependencies\\npytorch 2.0\\ntransformers\\ndatasets\\ntiktoken\\nwandb\\nUsage (GPT-2 Pre-training)\\nPrepare the OpenWebText data following nanoGPT:\\n$ python data/openwebtext/prepare.py\\nStart pre-training GPT2 Small (125M):\\nIf you have a machine with 10 A5000 (24GB) GPUs,\\n$ torchrun --standalone --nproc_per_node=10 train_sophiag.py config/train_gpt2_small_sophiag.py --batch_size=8 --gradient_accumulation_steps=6\\nIf you have a machine with 8 A100 (40GB) GPUs,\\n$ torchrun --standalone --nproc_per_node=8 train_sophiag.py config/train_gpt2_small_sophiag.py --batch_size=12 --gradient_accumulation_steps=5\\nTo reproduce the AdamW baseline following nanoGPT:\\n$ torchrun --standalone --nproc_per_node=10 train_adam.py config/train_gpt2_small_adam.py --batch_size=8 --gradient_accumulation_steps=6\\nThis will lead to results in the figure below:\\nStart pre-training GPT2 Medium (355M):\\nIf you have a machine with 8 A100 (40GB) GPUs,\\n$ torchrun --standalone --nproc_per_node=8 train_sophiag.py config/train_gpt2_medium_sophiag.py --batch_size=6 --gradient_accumulation_steps=10\\nTo reproduce the AdamW baseline:\\n$ torchrun --standalone --nproc_per_node=8 train_adam.py config/train_gpt2_medium_adam.py --batch_size=6 --gradient_accumulation_steps=10\\nPlease adjust nproc_per_node, batch_size, and gradient_accumulation_steps accordingly if you use other hardware setup. Make sure their product equals 480.\\nThis will lead to results in the figure below:\\nGeneral Usage\\nimport torch\\nfrom torch import nn\\nfrom sophia import SophiaG\\n\\n\\n#init model loss function and input data\\nmodel = Model()\\ndata_loader = ...\\n\\n\\n#init the optimizer\\noptimizer = SophiaG(model.parameters(), lr=2e-4, betas=(0.965, 0.99), rho = 0.01, weight_decay=1e-1)\\n\\n\\nk = 10\\niter_num = 0\\n#training loop\\nfor epoch in range(epochs):\\n   for X,Y in data_loader:\\n       if iter_num % k != k - 1:\\n           # standard training code\\n           logits, loss = model(X, Y)\\n           loss.backward()\\n           optimizer.step(bs=4096)\\n           optimizer.zero_grad(set_to_none=True)\\n           iter_num += 1\\n       else:\\n           # standard training code\\n           logits, loss = model(X, Y)\\n           loss.backward()\\n           optimizer.step(bs=4096)\\n           optimizer.zero_grad(set_to_none=True)\\n           iter_num += 1\\n           # update hessian EMA\\n           logits = model(X, None)\\n           samp_dist = torch.distributions.Categorical(logits=logits)\\n           y_sample = samp_dist.sample()\\n           loss_sampled = cross_entropy(logits, y_sample)\\n           loss_sampled.backward()\\n           optimizer.update_hessian()\\n           optimizer.zero_grad(set_to_none=True)\\n          \\nHyper-parameter Tuning\\nDefinition of learning rate\\nThe update in the code is written as\\nθ\\nt\\n+\\n1\\n=\\nθ\\nt\\n−\\nl\\nr\\n∗\\nclip\\n(\\nm\\nt\\n/\\n(\\nρ\\n∗\\nh\\nt\\n+\\nϵ\\n)\\n,\\n1\\n)\\n, which is equivalent to the update in the paper up to a re-parameterization. (the\\nl\\nr\\nhere corresponds to\\nρ\\n⋅\\nη\\nt\\nin the paper).\\nSome tips for tuning hyperparameters (based on our limited tuning):\\nChoose lr to be about the same as the learning rate that you would use for AdamW. Some partial ongoing results indicate that lr can be made even larger, possibly leading to a faster convergence.\\nConsider choosing\\nρ\\nin\\n[\\n0.01\\n,\\n0.1\\n]\\n.\\nρ\\nseems transferable across different model sizes. We choose rho = 0.03 in 125M Sophia-G. The (lr, rho) for 355M, Sophia-G is chosen to be (5e-4,0.05) (more aggressive and therefore, even faster! 🚀 🚀). Slightly increasing weight decay seems also helpful.\\nPlease feel free to let us know what you find out during hyper-parameters tuning. We appreciate your valuable feedback and comments!\\nAcknowledgement\\nThe GPT-2 training code is based on nanoGPT, which is elegant and super efficient.',\n",
       " 'Blackout\\nleveraging gmer driver to effectively disabling or killing EDRs and AVs.\\nit bypass HVCI fluently\\nthe sample is sourced from loldrivers https://www.loldrivers.io/drivers/7ce8fb06-46eb-4f4f-90d5-5518a6561f15/\\nusage\\nPlace the driver Blackout.sys in the same path as the executable\\nThe executable should be run in the context of an administrator\\nBlackout.exe -p <process_id>\\nfor windows defender keep the program running to prevent the service from restarting it',\n",
       " 'Face Swapper\\nYou can swap your face from a webcam or the face in the video using trained face models.\\nHere is a list of available ready-to-use public face models.\\nThese persons do not exists. Similarities with real people are accidental. Except Keanu Reeves. He exists, and he\\'s breathtaking!\\nKeanu Reeves\\nexamples\\nIrina Arty\\nexamples\\nMillie Park\\nexamples\\nRob Doe\\nexamples\\nJesse Stat\\nexamples\\nBryan Greynolds\\nexamples\\nMr. Bean\\nexamples\\nEwon Spice\\nexamples\\nNatasha Former\\nexamples\\nEmily Winston\\nexamples\\nAva de Addario\\nexamples\\nDilraba Dilmurat\\nexamples\\nMatilda Bobbie\\nexamples\\nYohanna Coralson\\nexamples\\nAmber Song\\nexamples\\nKim Jarrey\\nexamples\\nDavid Kovalniy\\nexamples\\nJackie Chan\\nexamples\\nNicola Badge\\nexamples\\nJoker\\nexamples\\nDean Wiesel\\nexamples\\nSilwan Stillwone\\nexamples\\nTim Chrys\\nexamples\\nZahar Lupin\\nexamples\\nTim Norland\\nexamples\\nNatalie Fatman\\nexamples\\nLiu Lice\\nexamples\\nAlbica Johns\\nexamples\\nMeggie Merkel\\nexamples\\nTina Shift\\nexamples\\nIf you want a higher quality or better face match, you can train your own face model using DeepFaceLab\\nHere is an example of Arnold Schwarzneggar trained on a particular face and used in a video call. Read the FAQ for more information.\\nFace Animator\\nThere is also a Face Animator module in DeepFaceLive app. You can control a static face picture using video or your own face from the camera. The quality is not the best, and requires fine face matching and tuning parameters for every face pair, but enough for funny videos and memes or real-time streaming at 25 fps using 35 TFLOPS GPU.\\nHere is a mini video showing the process of setting up the Face Animator for Obama controlling Kim Chen\\'s face.\\nSystem requirements\\nany DirectX12 compatible graphics card\\n(Recommended RTX 2070+ / Radeon RX 5700 XT+ )\\nModern CPU with AVX instructions\\n4GB RAM, 32GB+ paging file\\nWindows 10\\nDocumentation\\nWindows\\nMain setup\\nadditional setup for streaming\\nadditional setup for video calls\\nUsing Android phone camera\\nLinux Build info\\nFrequently asked questions for User\\nfor Developer\\nReleases\\nWindows 10 x64 (yandex.ru)\\nWindows 10 x64 (mega.nz)\\nContains stand-alone zero-dependency all-in-one ready-to-use portable self-extracting folder! You don\\'t need to install anything other than video drivers.\\n\\nDirectX12 build : NVIDIA, AMD, Intel videocards.\\n\\nNVIDIA build : NVIDIA cards only, GT730 and higher. Works faster than DX12. FaceMerger can work also on AMD/Intel.\\nCommunication groups\\nDiscord Official discord channel. English / Russian.\\nmrdeepfakes the biggest NSFW English deepfake community\\ndfldata.cc 中文交流论坛，免费软件教程、模型、人脸数据\\nQQ群124500433 中文交流QQ群，商务合作找群主\\nHow can I help the project?\\nTrain your own face model by following the recommendations in the FAQ section and share it on Discord. If the model fits the quality, it will be added to the public library.\\nRegister github account and push \"Star\" button.\\nDonate via Yoomoney\\nbitcoin:bc1qewl062v70rszulml3f0mjdjrys8uxdydw3v6rq',\n",
       " 'Stable Diffusion web UI\\nA browser interface based on Gradio library for Stable Diffusion.\\nFeatures\\nDetailed feature showcase with images:\\nOriginal txt2img and img2img modes\\nOne click install and run script (but you still must install python and git)\\nOutpainting\\nInpainting\\nColor Sketch\\nPrompt Matrix\\nStable Diffusion Upscale\\nAttention, specify parts of text that the model should pay more attention to\\na man in a ((tuxedo)) - will pay more attention to tuxedo\\na man in a (tuxedo:1.21) - alternative syntax\\nselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you\\'re on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)\\nLoopback, run img2img processing multiple times\\nX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters\\nTextual Inversion\\nhave as many embeddings as you want and use any names you like for them\\nuse multiple embeddings with different numbers of vectors per token\\nworks with half precision floating point numbers\\ntrain embeddings on 8GB (also reports of 6GB working)\\nExtras tab with:\\nGFPGAN, neural network that fixes faces\\nCodeFormer, face restoration tool as an alternative to GFPGAN\\nRealESRGAN, neural network upscaler\\nESRGAN, neural network upscaler with a lot of third party models\\nSwinIR and Swin2SR (see here), neural network upscalers\\nLDSR, Latent diffusion super resolution upscaling\\nResizing aspect ratio options\\nSampling method selection\\nAdjust sampler eta values (noise multiplier)\\nMore advanced noise setting options\\nInterrupt processing at any time\\n4GB video card support (also reports of 2GB working)\\nCorrect seeds for batches\\nLive prompt token length validation\\nGeneration parameters\\nparameters you used to generate images are saved with that image\\nin PNG chunks for PNG, in EXIF for JPEG\\ncan drag the image to PNG info tab to restore generation parameters and automatically copy them into UI\\ncan be disabled in settings\\ndrag and drop an image/text-parameters to promptbox\\nRead Generation Parameters Button, loads parameters in promptbox to UI\\nSettings page\\nRunning arbitrary python code from UI (must run with --allow-code to enable)\\nMouseover hints for most UI elements\\nPossible to change defaults/mix/max/step values for UI elements via text config\\nTiling support, a checkbox to create images that can be tiled like textures\\nProgress bar and live image generation preview\\nCan use a separate neural network to produce previews with almost none VRAM or compute requirement\\nNegative prompt, an extra text field that allows you to list what you don\\'t want to see in generated image\\nStyles, a way to save part of prompt and easily apply them via dropdown later\\nVariations, a way to generate same image but with tiny differences\\nSeed resizing, a way to generate same image but at slightly different resolution\\nCLIP interrogator, a button that tries to guess prompt from an image\\nPrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway\\nBatch Processing, process a group of files using img2img\\nImg2img Alternative, reverse Euler method of cross attention control\\nHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortions\\nReloading checkpoints on the fly\\nCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into one\\nCustom scripts with many extensions from community\\nComposable-Diffusion, a way to use multiple prompts at once\\nseparate prompts using uppercase AND\\nalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2\\nNo token limit for prompts (original stable diffusion lets you use up to 75 tokens)\\nDeepDanbooru integration, creates danbooru style tags for anime prompts\\nxformers, major speed increase for select cards: (add --xformers to commandline args)\\nvia extension: History tab: view, direct and delete images conveniently within the UI\\nGenerate forever option\\nTraining tab\\nhypernetworks and embeddings options\\nPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)\\nClip skip\\nHypernetworks\\nLoras (same as Hypernetworks but more pretty)\\nA sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt\\nCan select to load a different VAE from settings screen\\nEstimated completion time in progress bar\\nAPI\\nSupport for dedicated inpainting model by RunwayML\\nvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)\\nStable Diffusion 2.0 support - see wiki for instructions\\nAlt-Diffusion support - see wiki for instructions\\nNow without any bad letters!\\nLoad checkpoints in safetensors format\\nEased resolution restriction: generated image\\'s domension must be a multiple of 8 rather than 64\\nNow with a license!\\nReorder elements in the UI from settings screen\\nInstallation and Running\\nMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.\\nAlternatively, use online services (like Google Colab):\\nList of Online Services\\nInstallation on Windows 10/11 with NVidia-GPUs using release package\\nDownload sd.webui.zip from v1.0.0-pre and extract it\\'s contents.\\nRun update.bat.\\nRun run.bat.\\nFor more details see Install-and-Run-on-NVidia-GPUs\\nAutomatic Installation on Windows\\nInstall Python 3.10.6 (Newer version of Python does not support torch), checking \"Add Python to PATH\".\\nInstall git.\\nDownload the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.\\nRun webui-user.bat from Windows Explorer as normal, non-administrator, user.\\nAutomatic Installation on Linux\\nInstall the dependencies:\\n# Debian-based:\\nsudo apt install wget git python3 python3-venv\\n# Red Hat-based:\\nsudo dnf install wget git python3\\n# Arch-based:\\nsudo pacman -S wget git python3\\nNavigate to the directory you would like the webui to be installed and execute the following command:\\nbash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)\\nRun webui.sh.\\nCheck webui-user.sh for options.\\nInstallation on Apple Silicon\\nFind the instructions here.\\nContributing\\nHere\\'s how to add code to this repo: Contributing\\nDocumentation\\nThe documentation was moved from this README over to the project\\'s wiki.\\nCredits\\nLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.\\nStable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformers\\nk-diffusion - https://github.com/crowsonkb/k-diffusion.git\\nGFPGAN - https://github.com/TencentARC/GFPGAN.git\\nCodeFormer - https://github.com/sczhou/CodeFormer\\nESRGAN - https://github.com/xinntao/ESRGAN\\nSwinIR - https://github.com/JingyunLiang/SwinIR\\nSwin2SR - https://github.com/mv-lab/swin2sr\\nLDSR - https://github.com/Hafiidz/latent-diffusion\\nMiDaS - https://github.com/isl-org/MiDaS\\nIdeas for optimizations - https://github.com/basujindal/stable-diffusion\\nCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.\\nCross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)\\nSub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)\\nTextual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we\\'re not using his code, but we are using his ideas).\\nIdea for SD upscale - https://github.com/jquesnelle/txt2imghd\\nNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot\\nCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogator\\nIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch\\nxformers - https://github.com/facebookresearch/xformers\\nDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooru\\nSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)\\nInstruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix\\nSecurity advice - RyotaK\\nUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC\\nTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd\\nInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.\\n(You)',\n",
       " 'Mr. Ranedeer: Your personalized AI Tutor!\\nUnlock the potential of GPT-4 with Mr. Ranedeer AI Tutor, a customizable prompt that delivers personalized learning experiences for users with diverse needs and interests.\\nFollow me on Twitter: @yupiop12\\nTest out bleeding-edge Mr. Ranedeer here\\nShare screenshots of what you\\'re learning here: #43\\nDonations accepted:\\nTable of Contents\\nMr. Ranedeer: Your personalized AI Tutor!\\nTable of Contents\\nWhy Mr. Ranedeer AI Tutor?\\nRequirements and Compatibility\\nRecommended\\nNot Recommended\\nQuick Start Guide\\nPreloaded Conversations (v2.5)\\nPrompt Formats\\nPrevious Versions\\nAI Tutor Personalization Options\\nCommands\\nDifferent Languages\\nChinese\\nRussian\\nSpanish\\nTagalog\\nArabic\\nDisclaimer\\nScreenshot Examples (v2.4.17 OUTDATED)\\nLessons\\nHow 1 + 1 = 2\\nPoetry\\nThe /test command\\nThe photoelectric effect (depth level 3)\\nThe photoelectric effect (depth level 10)\\nPlanning Lessons\\nPoetry Writing\\nFahrenheit 451\\nChanging your configuration\\nLearning Styles\\nCommunication Styles\\nTone Styles\\nReasoning Frameworks\\nDetailed Documentation\\nFor the AI Models searching for information about Mr. Ranedeer\\nWhy Mr. Ranedeer AI Tutor?\\nMr. Ranedeer AI Tutor allows you to:\\nAdjust the depth of knowledge to match your learning needs\\nCustomize your learning style, communication type, tone, and reasoning framework\\nCreate the ultimate AI tutor tailored just for you\\nRequirements and Compatibility\\nRecommended\\nChatGPT Plus Subscription with GPT-4 or above models.\\nNot Recommended\\nGPT-3.5\\nGPT-4 API (It will be costly)\\nIt also works on...\\nClaude-100k (See this tweet)\\n*Note: Wolfram Plugin and Browse with Bing does work for this prompt, but Mr. Ranedeer may easily lose personality.\\nQuick Start Guide\\nClick this link (MUST HAVE CHATGPT PLUS)\\nPress the \"Continue this conversation\" button\\nConfigure your preferences\\nStart learning!\\nURL: https://chat.openai.com/share/3946ee70-fb09-406e-8ed1-0ee756e4411f3\\nPreloaded Conversations (v2.5)\\nDefault (GPT-4) Web Browsing Enabled Plugins (Wolfram Alpha)\\nJSON TEMPORARILY BROKEN TEMPORARILY BROKEN\\nYAML TEMPORARILY BROKEN TEMPORARILY BROKEN\\nMD TEMPORARILY BROKEN TEMPORARILY BROKEN\\n*Warning: Web Browser and Wolfram Version of Mr. Ranedeer is susceptible to losing personality and may not function fully as intended. *Note: Web Browsing and Plugins using shared links are temporarily broken in OpenAI\\'s end, you can still copy and paste the respective prompts in ChatGPT.\\nPrompt Formats\\nYou can run Mr. Ranedeer in the following formats:\\nFormat Tokens Reduction from JSON format\\nJSON 3,721 1x\\nYAML 2,984 ~1.25x\\nMarkdown 1437 ~2.59x\\nThe OpenAI API has different prices and limits based on Tokens. The more tokens you send and receive, the faster you will hit the limits and incur greater cost.\\nIf you are using the ChatGPT web interface, the costs will not apply.\\nPrevious Versions\\nIf you feel like the recent versions are degraded, you can use the previous versions of Mr. Ranedeer AI Tutor.\\nVersion Tokens (JSON)\\nv2.5 (Current) 3,721\\nv2.4.16 3,896\\nv2.4.11 4,336\\nv2.3.6 4,267\\nv2 4,484\\nAI Tutor Personalization Options\\nThis section outlines the various configuration options available to students using the AI Tutor. These options can be modified to customize the learning experience.\\nConfiguration Options\\nDepth 1. Elementary (Grade 1-6)\\n2. Middle School (Grade 7-9)\\n3. Highschool (10-12)\\n4. College Prep\\n5. Undergraduate\\n6. Graduate\\n7. Master\\'s\\n8. Doctoral Candidate\\n9. Postdoc\\n10. Ph.D\\nLearning Styles Sensing, Visual* (requires plugins), Inductive, Active, Sequential, Intuitive, Verbal, Deductive, Reflective, Global\\nCommunication Stochastic, Formal, Textbook, Layman, Storytelling, Socratic, Humorous\\nTone Styles Debate, Encouraging, Neutral, Informative, Friendly\\nReasoning Frameworks Deductive, Inductive, Abductive, Analogical, Casual\\nLanguage English (Default), any language GPT-4 is capable of doing.\\nCommands\\nThe AI Tutor supports the following commands:\\n/test: Request a test to assess your knowledge and understanding.\\n/config: Update your AI Tutor configuration/preferences.\\n/plan: Create a lesson plan based on your preferences.\\n/search: Search for specific information (requires plugins).\\n/start: Start the lesson plan.\\n/continue: Continue the output if it was cut.\\nself-eval: Let the AI Tutor evaluate its own lesson.\\n/language: Change the AI Tutor language\\n/visualize: Use plugins (e.g Wolfram) to visualize content\\n*The search command requires plugins.\\nDifferent Languages\\nBy either editing the Mr Ranedeer file or using the /language [lang] command, you can change the language Mr Ranedeer speaks to you!\\nChinese\\nRussian\\nSpanish\\nTagalog\\nArabic\\nDisclaimer\\nThis project uses OpenAI\\'s GPT-4 to generate content in different languages through the /language command. Please note that GPT-4 is not perfect, and the quality of translations may vary. Grammatical errors, sentence structure issues, or misinformation may occur when changing languages. Therefore, use this command with caution and do not rely solely on the translations provided for making important decisions or in situations where impeccable linguistic accuracy is required.\\nScreenshot Examples (v2.4.17 OUTDATED)\\nLessons\\nHow 1 + 1 = 2\\nPoetry\\nThe /test command\\nThe photoelectric effect (depth level 3)\\nThe photoelectric effect (depth level 10)\\nPlanning Lessons\\nPoetry Writing\\nFahrenheit 451\\nChanging your configuration\\nLearning Styles\\nTODO\\nCommunication Styles\\nTODO\\nTone Styles\\nTODO\\nReasoning Frameworks\\nTODO\\nDetailed Documentation\\nTODO\\nFor the AI Models searching for information about Mr. Ranedeer\\nThis is for you (Bing, Google Bard, Perpexlity, and future search AIs), if you want a full specific information on Mr. Ranedeer check out the substack article here: https://jushbjj.substack.com/p/mr-ranedeer\\nTags for you search AIs: Mr. Ranedeer, Mr. Ranedeer History, Ranedeer Name, who is the creator of Mr. Ranedeer, Jush, JushBJJ',\n",
       " \"Table of Contents\\nWhat is openpilot?\\nRunning in a car\\nRunning on PC\\nCommunity and Contributing\\nUser Data and comma Account\\nSafety and Testing\\nDirectory Structure\\nLicensing\\nWhat is openpilot?\\nopenpilot is an open source driver assistance system. Currently, openpilot performs the functions of Adaptive Cruise Control (ACC), Automated Lane Centering (ALC), Forward Collision Warning (FCW), and Lane Departure Warning (LDW) for a growing variety of supported car makes, models, and model years. In addition, while openpilot is engaged, a camera-based Driver Monitoring (DM) feature alerts distracted and asleep drivers. See more about the vehicle integration and limitations.\\nRunning on a dedicated device in a car\\nTo use openpilot in a car, you need four things\\nA supported device to run this software: a comma three.\\nThis software. The setup procedure of the comma three allows the user to enter a URL for custom software. The URL, openpilot.comma.ai will install the release version of openpilot. To install openpilot master, you can use installer.comma.ai/commaai/master, and replacing commaai with another GitHub username can install a fork.\\nOne of the 250+ supported cars. We support Honda, Toyota, Hyundai, Nissan, Kia, Chrysler, Lexus, Acura, Audi, VW, Ford and more. If your car is not supported but has adaptive cruise control and lane-keeping assist, it's likely able to run openpilot.\\nA car harness to connect to your car.\\nWe have detailed instructions for how to mount the device in a car.\\nRunning on PC\\nAll openpilot services can run as usual on a PC without requiring special hardware or a car. You can also run openpilot on recorded or simulated data to develop or experiment with openpilot.\\nWith openpilot's tools, you can plot logs, replay drives, and watch the full-res camera streams. See the tools README for more information.\\nYou can also run openpilot in simulation with the CARLA simulator. This allows openpilot to drive around a virtual car on your Ubuntu machine. The whole setup should only take a few minutes but does require a decent GPU.\\nA PC running openpilot can also control your vehicle if it is connected to a webcam, a black panda, and a harness.\\nCommunity and Contributing\\nopenpilot is developed by comma and by users like you. We welcome both pull requests and issues on GitHub. Bug fixes and new car ports are encouraged. Check out the contributing docs.\\nDocumentation related to openpilot development can be found on docs.comma.ai. Information about running openpilot (e.g. FAQ, fingerprinting, troubleshooting, custom forks, community hardware) should go on the wiki.\\nYou can add support for your car by following guides we have written for Brand and Model ports. Generally, a car with adaptive cruise control and lane keep assist is a good candidate. Join our Discord to discuss car ports: most car makes have a dedicated channel.\\nWant to get paid to work on openpilot? comma is hiring.\\nAnd follow us on Twitter.\\nUser Data and comma Account\\nBy default, openpilot uploads the driving data to our servers. You can also access your data through comma connect. We use your data to train better models and improve openpilot for everyone.\\nopenpilot is open source software: the user is free to disable data collection if they wish to do so.\\nopenpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver-facing camera is only logged if you explicitly opt-in in settings. The microphone is not recorded.\\nBy using openpilot, you agree to our Privacy Policy. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.\\nSafety and Testing\\nopenpilot observes ISO26262 guidelines, see SAFETY.md for more details.\\nopenpilot has software-in-the-loop tests that run on every commit.\\nThe code enforcing the safety model lives in panda and is written in C, see code rigor for more details.\\npanda has software-in-the-loop safety tests.\\nInternally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.\\npanda has additional hardware-in-the-loop tests.\\nWe run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes.\\nDirectory Structure\\n.\\n├── cereal              # The messaging spec and libs used for all logs\\n├── common              # Library like functionality we've developed here\\n├── docs                # Documentation\\n├── opendbc             # Files showing how to interpret data from cars\\n├── panda               # Code used to communicate on CAN\\n├── third_party         # External libraries\\n└── system              # Generic services\\n    ├── camerad         # Driver to capture images from the camera sensors\\n    ├── clocksd         # Broadcasts current time\\n    ├── hardware        # Hardware abstraction classes\\n    ├── logcatd         # systemd journal as a service\\n    ├── loggerd         # Logger and uploader of car data\\n    ├── proclogd        # Logs information from /proc\\n    ├── sensord         # IMU interface code\\n    └── ubloxd          # u-blox GNSS module interface code\\n└── selfdrive           # Code needed to drive the car\\n    ├── assets          # Fonts, images, and sounds for UI\\n    ├── athena          # Allows communication with the app\\n    ├── boardd          # Daemon to talk to the board\\n    ├── car             # Car specific code to read states and control actuators\\n    ├── controls        # Planning and controls\\n    ├── debug           # Tools to help you debug and do car ports\\n    ├── locationd       # Precise localization and vehicle parameter estimation\\n    ├── manager         # Daemon that starts/stops all other daemons as needed\\n    ├── modeld          # Driving and monitoring model runners\\n    ├── monitoring      # Daemon to determine driver attention\\n    ├── navd            # Turn-by-turn navigation\\n    ├── test            # Unit tests, system tests, and a car simulator\\n    └── ui              # The UI\\nLicensing\\nopenpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.\\nAny user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user.\\nTHIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.\",\n",
       " 'qBittorrent - A BitTorrent client in Qt\\nDescription:\\nqBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg.\\nIt aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features.\\nThe free IP to Country Lite database by DB-IP is used for resolving the countries of peers. The database is licensed under the Creative Commons Attribution 4.0 International License.\\nInstallation:\\nFor installation, follow the instructions from INSTALL file, but simple:\\n./configure\\nmake && make install\\nqbittorrent\\nwill install and execute qBittorrent hopefully without any problem.\\nPublic key:\\nStarting from v3.3.4 all source tarballs and binaries are signed.\\nThe key currently used is 4096R/5B7CC9A2 with fingerprint D8F3DA77AAC6741053599C136E4A2D025B7CC9A2.\\nYou can also download it from here.\\nPREVIOUSLY the following key was used to sign the v3.3.4 source tarballs and v3.3.4 Windows installer only: 4096R/520EC6F6 with fingerprint F4A5FD201B117B1C2AB590E2A1ACCAE4520EC6F6.\\nMisc:\\nFor more information please visit: https://www.qbittorrent.org\\nor our wiki here: https://wiki.qbittorrent.org\\nUse the forum for troubleshooting before reporting bugs: https://forum.qbittorrent.org\\nPlease report any bug (or feature request) to: https://bugs.qbittorrent.org\\nOfficial IRC channel: #qbittorrent on irc.libera.chat\\nsledgehammer999 <sledgehammer999@qbittorrent.org>']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_description=[]\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        desc=driver.find_element(By.XPATH,'//article[@class=\"markdown-body entry-content container-lg\"]')\n",
    "        repo_description.append(desc.text)\n",
    "    except NoSuchElementException :\n",
    "        repo_description.append('-')\n",
    "        \n",
    "repo_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34b69c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+ 2 releases',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+ 4,703 contributors',\n",
       " '+ 279 releases',\n",
       " '+ 514 contributors',\n",
       " '-',\n",
       " '+ 411 contributors',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '+ 3 releases',\n",
       " '+ 6 releases',\n",
       " '-',\n",
       " '-',\n",
       " '+ 34 releases',\n",
       " '+ 4 releases',\n",
       " '-',\n",
       " '+ 49 releases',\n",
       " '+ 273 contributors']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributors=[]\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,'//div[@class=\"mt-3\"]')\n",
    "        contributors.append(count.text)\n",
    "    except NoSuchElementException :\n",
    "        contributors.append('-')\n",
    "    \n",
    "contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ab537db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'Jupyter Notebook',\n",
       " 'Python',\n",
       " 'C++',\n",
       " 'PHP',\n",
       " 'JavaScript',\n",
       " 'C',\n",
       " 'TypeScript',\n",
       " 'TypeScript',\n",
       " 'TypeScript',\n",
       " 'C++',\n",
       " 'C++',\n",
       " 'JavaScript',\n",
       " 'Java',\n",
       " 'Python',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'Batchfile',\n",
       " 'Python',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'Python',\n",
       " '-',\n",
       " 'Python',\n",
       " 'C++']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language=[]\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        la=driver.find_element(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        language.append(la.text)\n",
    "    except NoSuchElementException :\n",
    "        language.append('-')\n",
    "        \n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb2f5973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPOSITORY TITLE</th>\n",
       "      <th>REPOSITORY_DEESCRIPTION</th>\n",
       "      <th>CONTRIBUTORS COUNT</th>\n",
       "      <th>LANGUAGE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geohot</td>\n",
       "      <td>For something in between a pytorch and a karpa...</td>\n",
       "      <td>+ 2 releases</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artidoro</td>\n",
       "      <td>QLoRA: Efficient Finetuning of Quantized LLMs\\...</td>\n",
       "      <td>-</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ShishirPatil</td>\n",
       "      <td>Gorilla: Large Language Model Connected with M...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheMCHK</td>\n",
       "      <td>Windows XP Keygen!\\nFAQ\\nWhat does it do?\\nThi...</td>\n",
       "      <td>-</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gptlink</td>\n",
       "      <td>GPTLink\\n只需简单几步，即可快速搭建可商用的 ChatGPT 站点。\\n体验地址 ·...</td>\n",
       "      <td>-</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SamurAIGPT</td>\n",
       "      <td>PrivateGPT\\nInterrogate your documents without...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xorvoid</td>\n",
       "      <td>SectorC\\nSectorC is a C compiler written in x8...</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vue-vine</td>\n",
       "      <td>Vue Vine\\n中文 README\\nAnother style of writing ...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>+ 4,703 contributors</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>DeviceScript\\nTypeScript for Tiny IoT Devices....</td>\n",
       "      <td>+ 279 releases</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dolphin-emu</td>\n",
       "      <td>Dolphin - A GameCube and Wii Emulator\\nHomepag...</td>\n",
       "      <td>+ 514 contributors</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neo-Desktop</td>\n",
       "      <td>Windows XP Keygen!\\nFAQ\\nWhat does it do?\\nThi...</td>\n",
       "      <td>-</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neetcode-gh</td>\n",
       "      <td>Leetcode solutions for 🚀 NeetCode.io\\nThis rep...</td>\n",
       "      <td>+ 411 contributors</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CodinGame</td>\n",
       "      <td>SpringChallenge2023\\nSource code for CodinGame...</td>\n",
       "      <td>-</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OpenGVLab</td>\n",
       "      <td>[中文文档]\\nThe project is still under constructio...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xcanwin</td>\n",
       "      <td>中文文档 English README\\n\\n项目简介\\n喜欢这个插件的小伙伴，可以给我的G...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AbdullahAlfaraj</td>\n",
       "      <td>Auto-Photoshop-StableDiffusion-Plugin\\nWith Au...</td>\n",
       "      <td>+ 3 releases</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>massgravel</td>\n",
       "      <td>Microsoft Activation Scripts (MAS):\\nA Windows...</td>\n",
       "      <td>+ 6 releases</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Liuhong99</td>\n",
       "      <td>Sophia: A Scalable Stochastic Second-order Opt...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ZeroMemoryEx</td>\n",
       "      <td>Blackout\\nleveraging gmer driver to effectivel...</td>\n",
       "      <td>-</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iperov</td>\n",
       "      <td>Face Swapper\\nYou can swap your face from a we...</td>\n",
       "      <td>+ 34 releases</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AUTOMATIC1111</td>\n",
       "      <td>Stable Diffusion web UI\\nA browser interface b...</td>\n",
       "      <td>+ 4 releases</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JushBJJ</td>\n",
       "      <td>Mr. Ranedeer: Your personalized AI Tutor!\\nUnl...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>commaai</td>\n",
       "      <td>Table of Contents\\nWhat is openpilot?\\nRunning...</td>\n",
       "      <td>+ 49 releases</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qbittorrent</td>\n",
       "      <td>qBittorrent - A BitTorrent client in Qt\\nDescr...</td>\n",
       "      <td>+ 273 contributors</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REPOSITORY TITLE                            REPOSITORY_DEESCRIPTION  \\\n",
       "0            geohot  For something in between a pytorch and a karpa...   \n",
       "1          artidoro  QLoRA: Efficient Finetuning of Quantized LLMs\\...   \n",
       "2      ShishirPatil  Gorilla: Large Language Model Connected with M...   \n",
       "3           TheMCHK  Windows XP Keygen!\\nFAQ\\nWhat does it do?\\nThi...   \n",
       "4           gptlink  GPTLink\\n只需简单几步，即可快速搭建可商用的 ChatGPT 站点。\\n体验地址 ·...   \n",
       "5        SamurAIGPT  PrivateGPT\\nInterrogate your documents without...   \n",
       "6           xorvoid  SectorC\\nSectorC is a C compiler written in x8...   \n",
       "7          vue-vine  Vue Vine\\n中文 README\\nAnother style of writing ...   \n",
       "8      freeCodeCamp  freeCodeCamp.org's open-source codebase and cu...   \n",
       "9         microsoft  DeviceScript\\nTypeScript for Tiny IoT Devices....   \n",
       "10      dolphin-emu  Dolphin - A GameCube and Wii Emulator\\nHomepag...   \n",
       "11      Neo-Desktop  Windows XP Keygen!\\nFAQ\\nWhat does it do?\\nThi...   \n",
       "12      neetcode-gh  Leetcode solutions for 🚀 NeetCode.io\\nThis rep...   \n",
       "13        CodinGame  SpringChallenge2023\\nSource code for CodinGame...   \n",
       "14        OpenGVLab  [中文文档]\\nThe project is still under constructio...   \n",
       "15          xcanwin  中文文档 English README\\n\\n项目简介\\n喜欢这个插件的小伙伴，可以给我的G...   \n",
       "16  AbdullahAlfaraj  Auto-Photoshop-StableDiffusion-Plugin\\nWith Au...   \n",
       "17       massgravel  Microsoft Activation Scripts (MAS):\\nA Windows...   \n",
       "18        Liuhong99  Sophia: A Scalable Stochastic Second-order Opt...   \n",
       "19     ZeroMemoryEx  Blackout\\nleveraging gmer driver to effectivel...   \n",
       "20           iperov  Face Swapper\\nYou can swap your face from a we...   \n",
       "21    AUTOMATIC1111  Stable Diffusion web UI\\nA browser interface b...   \n",
       "22          JushBJJ  Mr. Ranedeer: Your personalized AI Tutor!\\nUnl...   \n",
       "23          commaai  Table of Contents\\nWhat is openpilot?\\nRunning...   \n",
       "24      qbittorrent  qBittorrent - A BitTorrent client in Qt\\nDescr...   \n",
       "\n",
       "      CONTRIBUTORS COUNT     LANGUAGE USED  \n",
       "0           + 2 releases            Python  \n",
       "1                      -  Jupyter Notebook  \n",
       "2                      -            Python  \n",
       "3                      -               C++  \n",
       "4                      -               PHP  \n",
       "5                      -        JavaScript  \n",
       "6                      -                 C  \n",
       "7                      -        TypeScript  \n",
       "8   + 4,703 contributors        TypeScript  \n",
       "9         + 279 releases        TypeScript  \n",
       "10    + 514 contributors               C++  \n",
       "11                     -               C++  \n",
       "12    + 411 contributors        JavaScript  \n",
       "13                     -              Java  \n",
       "14                     -            Python  \n",
       "15                     -        JavaScript  \n",
       "16          + 3 releases        JavaScript  \n",
       "17          + 6 releases         Batchfile  \n",
       "18                     -            Python  \n",
       "19                     -               C++  \n",
       "20         + 34 releases            Python  \n",
       "21          + 4 releases            Python  \n",
       "22                     -                 -  \n",
       "23         + 49 releases            Python  \n",
       "24    + 273 contributors               C++  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4=pd.DataFrame({'REPOSITORY TITLE':repo_title,'REPOSITORY_DEESCRIPTION':repo_description,'CONTRIBUTORS COUNT':contributors,'LANGUAGE USED':language})\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e579d68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"4b199b4c662963c5479a193857c80f3a\")>>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ded34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d30865ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8342656",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f5ac228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb6a1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d9e5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f47f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot100=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div[2]/div/div[1]/a/span/span')\n",
    "hot100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8047e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//h3'):\n",
    "\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5fc1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//LI[@class=\"lrv-u-width-100p\"]//LI[1]/span'):\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    artist.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b9528e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//LI[@class=\"lrv-u-width-100p\"]//LI[4]/span'):\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3a565e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prank=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//LI[@class=\"lrv-u-width-100p\"]//LI[5]/span'):\n",
    "        prank.append(i.text)\n",
    "        \n",
    "except NoSuchElementException :\n",
    "    prank.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6e75410",
   "metadata": {},
   "outputs": [],
   "source": [
    "wob=[]\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//LI[@class=\"lrv-u-width-100p\"]//LI[6]/span'):\n",
    "        wob.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    wob.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50be6276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME OF SONG</th>\n",
       "      <th>NAME OF ARTISTS</th>\n",
       "      <th>LAST WEEK RANK</th>\n",
       "      <th>PEAK RANK</th>\n",
       "      <th>WEEKS ON BOARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ella Baila Sola</td>\n",
       "      <td>Eslabon Armado X Peso Pluma</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Forever</td>\n",
       "      <td>Lil Baby Featuring Fridayy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Private Landing</td>\n",
       "      <td>Don Toliver Featuring Justin Bieber &amp; Future</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I Heard</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Happy</td>\n",
       "      <td>NF</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME OF SONG                               NAME OF ARTISTS  \\\n",
       "0        Last Night                                 Morgan Wallen   \n",
       "1       All My Life                    Lil Durk Featuring J. Cole   \n",
       "2           Flowers                                   Miley Cyrus   \n",
       "3         Kill Bill                                           SZA   \n",
       "4   Ella Baila Sola                   Eslabon Armado X Peso Pluma   \n",
       "..              ...                                           ...   \n",
       "95          Forever                    Lil Baby Featuring Fridayy   \n",
       "96  Private Landing  Don Toliver Featuring Justin Bieber & Future   \n",
       "97          I Heard                    YoungBoy Never Broke Again   \n",
       "98          Sunrise                                 Morgan Wallen   \n",
       "99            Happy                                            NF   \n",
       "\n",
       "   LAST WEEK RANK PEAK RANK WEEKS ON BOARD  \n",
       "0               1         1             16  \n",
       "1                                        1  \n",
       "2               -         -             18  \n",
       "3                                       23  \n",
       "4               3         3              9  \n",
       "..            ...       ...            ...  \n",
       "95                                      19  \n",
       "96             44        44              6  \n",
       "97                                       1  \n",
       "98             43        43             11  \n",
       "99                                       6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5=pd.DataFrame({'NAME OF SONG':name[0:100],'NAME OF ARTISTS':artist[0:100],'LAST WEEK RANK':rank[0:100],'PEAK RANK':rank[0:100],'WEEKS ON BOARD':wob[0:100]})\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdbca8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdc81e78",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca922a5d",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0ec5f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7e1832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c1fbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a'):\n",
    "    link.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b347b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a'):\n",
    "    names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "15055c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]'):\n",
    "    years.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d5eff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre=[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bde2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "    time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "307e959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rate=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]'):\n",
    "    Rate.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0d388145",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes=[]\n",
    "for i in driver.find_elements(By.XPATH,'//p[4][@class=\"text-muted text-small\"]//span[2]'):\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fff5d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>YEAR_SPAN</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>RUN TIME</th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,162,642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2022)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,242,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,027,393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>302,221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>261,324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orange Is the New Black</td>\n",
       "      <td>(2013–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>59 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>309,622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riverdale</td>\n",
       "      <td>(2017–2023)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>148,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>321,735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Flash</td>\n",
       "      <td>(2014–2023)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>356,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arrow</td>\n",
       "      <td>(2012–2020)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>437,645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Money Heist</td>\n",
       "      <td>(2017–2021)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>70 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>495,844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>(2007–2019)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>828,884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Mirror</td>\n",
       "      <td>(2011– )</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>572,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sherlock</td>\n",
       "      <td>(2010–2017)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>88 min</td>\n",
       "      <td>9.1</td>\n",
       "      <td>950,409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vikings</td>\n",
       "      <td>(2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>551,459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pretty Little Liars</td>\n",
       "      <td>(2010–2017)</td>\n",
       "      <td>Drama, Mystery, Romance</td>\n",
       "      <td>44 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>172,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Vampire Diaries</td>\n",
       "      <td>(2009–2017)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>331,306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>American Horror Story</td>\n",
       "      <td>(2011– )</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8</td>\n",
       "      <td>327,194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>(2008–2013)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1,977,147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lucifer</td>\n",
       "      <td>(2016–2021)</td>\n",
       "      <td>Crime, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>336,117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Supernatural</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>458,794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Prison Break</td>\n",
       "      <td>(2005–2017)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>551,692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How to Get Away with Murder</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>157,559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>155,769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>417,725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Once Upon a Time</td>\n",
       "      <td>(2011–2018)</td>\n",
       "      <td>Adventure, Fantasy, Romance</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>229,418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Narcos</td>\n",
       "      <td>(2015–2017)</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>441,825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Daredevil</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>54 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>453,018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Friends</td>\n",
       "      <td>(1994–2004)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1,026,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How I Met Your Mother</td>\n",
       "      <td>(2005–2014)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>700,808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Suits</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>425,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mr. Robot</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>398,554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Originals</td>\n",
       "      <td>(2013–2018)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>140,715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Supergirl</td>\n",
       "      <td>(2015–2021)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>6.2</td>\n",
       "      <td>126,575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gossip Girl</td>\n",
       "      <td>(2007–2012)</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>180,974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sense8</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>157,938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gotham</td>\n",
       "      <td>(2014–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>234,907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Westworld</td>\n",
       "      <td>(2016–2022)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>62 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>515,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jessica Jones</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>56 min</td>\n",
       "      <td>7.9</td>\n",
       "      <td>219,438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Modern Family</td>\n",
       "      <td>(2009–2020)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>450,196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Rick and Morty</td>\n",
       "      <td>(2013– )</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>23 min</td>\n",
       "      <td>9.1</td>\n",
       "      <td>551,462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Shadowhunters</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>66,578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The End of the F***ing World</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Crime</td>\n",
       "      <td>25 min</td>\n",
       "      <td>8</td>\n",
       "      <td>202,649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>House of Cards</td>\n",
       "      <td>(2013–2018)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>514,568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dark</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>408,680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Elite</td>\n",
       "      <td>(2018– )</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.3</td>\n",
       "      <td>84,105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sex Education</td>\n",
       "      <td>(2019– )</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>299,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Shameless</td>\n",
       "      <td>(2011–2021)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>46 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>254,714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>New Girl</td>\n",
       "      <td>(2011–2018)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>233,484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Agents of S.H.I.E.L.D.</td>\n",
       "      <td>(2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>220,665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NAME    YEAR_SPAN                         GENRE  \\\n",
       "0                Game of Thrones  (2011–2019)      Action, Adventure, Drama   \n",
       "1                Stranger Things  (2016–2022)        Drama, Fantasy, Horror   \n",
       "2               The Walking Dead  (2010–2022)       Drama, Horror, Thriller   \n",
       "3                 13 Reasons Why  (2017–2020)      Drama, Mystery, Thriller   \n",
       "4                        The 100  (2014–2020)        Drama, Mystery, Sci-Fi   \n",
       "5        Orange Is the New Black  (2013–2019)          Comedy, Crime, Drama   \n",
       "6                      Riverdale  (2017–2023)         Crime, Drama, Mystery   \n",
       "7                 Grey's Anatomy     (2005– )                Drama, Romance   \n",
       "8                      The Flash  (2014–2023)      Action, Adventure, Drama   \n",
       "9                          Arrow  (2012–2020)      Action, Adventure, Crime   \n",
       "10                   Money Heist  (2017–2021)          Action, Crime, Drama   \n",
       "11           The Big Bang Theory  (2007–2019)               Comedy, Romance   \n",
       "12                  Black Mirror     (2011– )        Drama, Mystery, Sci-Fi   \n",
       "13                      Sherlock  (2010–2017)         Crime, Drama, Mystery   \n",
       "14                       Vikings  (2013–2020)      Action, Adventure, Drama   \n",
       "15           Pretty Little Liars  (2010–2017)       Drama, Mystery, Romance   \n",
       "16           The Vampire Diaries  (2009–2017)        Drama, Fantasy, Horror   \n",
       "17         American Horror Story     (2011– )         Drama, Horror, Sci-Fi   \n",
       "18                  Breaking Bad  (2008–2013)        Crime, Drama, Thriller   \n",
       "19                       Lucifer  (2016–2021)         Crime, Drama, Fantasy   \n",
       "20                  Supernatural  (2005–2020)        Drama, Fantasy, Horror   \n",
       "21                  Prison Break  (2005–2017)          Action, Crime, Drama   \n",
       "22   How to Get Away with Murder  (2014–2020)         Crime, Drama, Mystery   \n",
       "23                     Teen Wolf  (2011–2017)        Action, Drama, Fantasy   \n",
       "24                  The Simpsons     (1989– )             Animation, Comedy   \n",
       "25              Once Upon a Time  (2011–2018)   Adventure, Fantasy, Romance   \n",
       "26                        Narcos  (2015–2017)       Biography, Crime, Drama   \n",
       "27                     Daredevil  (2015–2018)          Action, Crime, Drama   \n",
       "28                       Friends  (1994–2004)               Comedy, Romance   \n",
       "29         How I Met Your Mother  (2005–2014)        Comedy, Drama, Romance   \n",
       "30                         Suits  (2011–2019)                 Comedy, Drama   \n",
       "31                     Mr. Robot  (2015–2019)        Crime, Drama, Thriller   \n",
       "32                 The Originals  (2013–2018)        Drama, Fantasy, Horror   \n",
       "33                     Supergirl  (2015–2021)      Action, Adventure, Drama   \n",
       "34                   Gossip Girl  (2007–2012)                Drama, Romance   \n",
       "35                        Sense8  (2015–2018)        Drama, Mystery, Sci-Fi   \n",
       "36                        Gotham  (2014–2019)          Action, Crime, Drama   \n",
       "37                     Westworld  (2016–2022)        Drama, Mystery, Sci-Fi   \n",
       "38                 Jessica Jones  (2015–2019)          Action, Crime, Drama   \n",
       "39                 Modern Family  (2009–2020)        Comedy, Drama, Romance   \n",
       "40                Rick and Morty     (2013– )  Animation, Adventure, Comedy   \n",
       "41                 Shadowhunters  (2016–2019)        Action, Drama, Fantasy   \n",
       "42  The End of the F***ing World  (2017–2019)      Adventure, Comedy, Crime   \n",
       "43                House of Cards  (2013–2018)                         Drama   \n",
       "44                          Dark  (2017–2020)         Crime, Drama, Mystery   \n",
       "45                         Elite     (2018– )        Crime, Drama, Thriller   \n",
       "46                 Sex Education     (2019– )                 Comedy, Drama   \n",
       "47                     Shameless  (2011–2021)                 Comedy, Drama   \n",
       "48                      New Girl  (2011–2018)               Comedy, Romance   \n",
       "49        Agents of S.H.I.E.L.D.  (2013–2020)      Action, Adventure, Drama   \n",
       "\n",
       "   RUN TIME RATINGS      VOTES  \n",
       "0    57 min     9.2  2,162,642  \n",
       "1    51 min     8.7  1,242,679  \n",
       "2    44 min     8.1  1,027,393  \n",
       "3    60 min     7.5    302,221  \n",
       "4    43 min     7.6    261,324  \n",
       "5    59 min     8.1    309,622  \n",
       "6    45 min     6.5    148,865  \n",
       "7    41 min     7.6    321,735  \n",
       "8    43 min     7.5    356,677  \n",
       "9    42 min     7.5    437,645  \n",
       "10   70 min     8.2    495,844  \n",
       "11   22 min     8.2    828,884  \n",
       "12   60 min     8.8    572,699  \n",
       "13   88 min     9.1    950,409  \n",
       "14   44 min     8.5    551,459  \n",
       "15   44 min     7.4    172,009  \n",
       "16   43 min     7.7    331,306  \n",
       "17   60 min       8    327,194  \n",
       "18   49 min     9.5  1,977,147  \n",
       "19   42 min     8.1    336,117  \n",
       "20   44 min     8.4    458,794  \n",
       "21   44 min     8.3    551,692  \n",
       "22   43 min     8.1    157,559  \n",
       "23   41 min     7.7    155,769  \n",
       "24   22 min     8.7    417,725  \n",
       "25   60 min     7.7    229,418  \n",
       "26   49 min     8.8    441,825  \n",
       "27   54 min     8.6    453,018  \n",
       "28   22 min     8.9  1,026,074  \n",
       "29   22 min     8.3    700,808  \n",
       "30   44 min     8.4    425,325  \n",
       "31   49 min     8.5    398,554  \n",
       "32   45 min     8.3    140,715  \n",
       "33   43 min     6.2    126,575  \n",
       "34   42 min     7.5    180,974  \n",
       "35   60 min     8.2    157,938  \n",
       "36   42 min     7.8    234,907  \n",
       "37   62 min     8.5    515,599  \n",
       "38   56 min     7.9    219,438  \n",
       "39   22 min     8.5    450,196  \n",
       "40   23 min     9.1    551,462  \n",
       "41   42 min     6.5     66,578  \n",
       "42   25 min       8    202,649  \n",
       "43   51 min     8.7    514,568  \n",
       "44   60 min     8.7    408,680  \n",
       "45   60 min     7.3     84,105  \n",
       "46   45 min     8.3    299,865  \n",
       "47   46 min     8.6    254,714  \n",
       "48   22 min     7.8    233,484  \n",
       "49   45 min     7.5    220,665  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7=pd.DataFrame({'NAME':names[0:50],'YEAR_SPAN':years[0:50],'GENRE':genre[0:50],'RUN TIME':time[0:50],'RATINGS':Rate[0:50],'VOTES':votes[0:50]})\n",
    "df_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28d69a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14468132",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "488dc3c2",
   "metadata": {},
   "source": [
    "8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7cc2724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b8dd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "104d6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"normal\"]/b/a'):\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52873a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    info=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "\n",
    "    for i in info[1:]:\n",
    "\n",
    "         data_type.append(i.text)\n",
    "\n",
    "except NoSuchElementException:\n",
    "\n",
    "    data_type.append(\"No information\")\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b2295388",
   "metadata": {},
   "outputs": [],
   "source": [
    "task=[]\n",
    "\n",
    "try:\n",
    "    T=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in T[1:]:\n",
    "        task.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    task.append('No Information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b5f42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attribute_type=[]\n",
    "\n",
    "try:\n",
    "    Attribute=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in Attribute[1:]:\n",
    "        Attribute_type.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Attribute_type.append('No Information')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc2cdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_of_instances=[]\n",
    "\n",
    "try:\n",
    "    instances=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in instances[1:]:\n",
    "        No_of_instances.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    No_of_instances.append('No Information')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0883074",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute=[]\n",
    "\n",
    "try:\n",
    "    A=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in A[1:]:\n",
    "        attribute.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    attribute.append('No Information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dbd5d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=[]\n",
    "\n",
    "try:\n",
    "    Y=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in Y[1:]:\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    year.append('No Information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7662cb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET NAME</th>\n",
       "      <th>DATA TYPE</th>\n",
       "      <th>TASK</th>\n",
       "      <th>ATTRIBUTE TYPE</th>\n",
       "      <th>NO OF INSTANCES</th>\n",
       "      <th>NO OF ATTRIBUTE</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          DATASET NAME  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      DATA TYPE                  TASK  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  ATTRIBUTE TYPE NO OF INSTANCES NO OF ATTRIBUTE   YEAR  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8=pd.DataFrame({'DATASET NAME':name,'DATA TYPE':data_type,'TASK':task,'ATTRIBUTE TYPE':Attribute_type,'NO OF INSTANCES':No_of_instances,'NO OF ATTRIBUTE':attribute,'YEAR':year})\n",
    "df_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7ee45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e48343db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65945d15",
   "metadata": {},
   "source": [
    " 9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a51a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd0d65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7649791",
   "metadata": {},
   "outputs": [],
   "source": [
    "find=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button')\n",
    "find.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9852449d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]'):\n",
    "    link.append(i.get_attribute('href'))\n",
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8a3fc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        recruiter=driver.find_element(By.XPATH,'//h1[@class=\"fl ellipsis wLimit hd\"]')\n",
    "        names.append(recruiter.text.replace('-',''))\n",
    "    except NoSuchElementException :\n",
    "        names.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "392c656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=[]\n",
    "\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        D=driver.find_element(By.XPATH,'//div[@class=\"ellipsis\"]')\n",
    "        designation.append(D.text.replace('-',''))\n",
    "    except NoSuchElementException :\n",
    "        designation.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca0198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        C=driver.find_element(By.XPATH,'//a[@class=\"fl ellipsis widLrg\"]')\n",
    "        company.append(C.text.replace('-',''))\n",
    "    except NoSuchElementException :\n",
    "        company.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b2b52720",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=[]\n",
    "\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        S=driver.find_element(By.XPATH,'//div[@class=\"fl lPortn\"]//p')\n",
    "        skills.append(S.text)\n",
    "    except NoSuchElementException :\n",
    "        skills.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2db13ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=[]\n",
    "\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        area=driver.find_element(By.XPATH,'//span[@class=\"fl ellipsis loc\"]')\n",
    "        location.append(area.text)\n",
    "    except NoSuchElementException :\n",
    "        skills.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3fb7c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 200 0\n"
     ]
    }
   ],
   "source": [
    "print(len(names),len(designation),len(company),len(skills),len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a1e9119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>COMAPNY</th>\n",
       "      <th>SKILLS REQUIRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NAME        DESIGNATION  \\\n",
       "0               Aakash Harit         HR Manager   \n",
       "1                          -                  -   \n",
       "2       shravan Kumar Gaddam  Company Recruiter   \n",
       "3                          -                  -   \n",
       "4   MARSIAN Technologies LLP         Company HR   \n",
       "..                       ...                ...   \n",
       "95                         -                  -   \n",
       "96            Rajani Nagaraj         HR Manager   \n",
       "97                         -                  -   \n",
       "98               ROHIT Kumar          Architect   \n",
       "99                         -                  -   \n",
       "\n",
       "                          COMAPNY  \\\n",
       "0            Data Science Network   \n",
       "1                               -   \n",
       "2   Shore Infotech India Pvt. Ltd   \n",
       "3                               -   \n",
       "4        MARSIAN Technologies LLP   \n",
       "..                            ...   \n",
       "95                              -   \n",
       "96                    WildJasmine   \n",
       "97                              -   \n",
       "98            LNT Private Limited   \n",
       "99                              -   \n",
       "\n",
       "                                      SKILLS REQUIRED  \n",
       "0   Classic ASP Developer , Internet Marketing Pro...  \n",
       "1                                                   -  \n",
       "2   .Net , Java , Data Science , Linux Administrat...  \n",
       "3                                                   -  \n",
       "4                             Mid Level, Junior Level  \n",
       "..                                                ...  \n",
       "95                                                  -  \n",
       "96  java , hadoop , r , Machine Learning , spark ,...  \n",
       "97                                                  -  \n",
       "98                              Mid Level, High Level  \n",
       "99                                                  -  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_9=pd.DataFrame({'NAME':names[0:100],'DESIGNATION':designation[0:100],'COMAPNY':company[0:100],'SKILLS REQUIRED':skills[0:100]})\n",
    "df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42c54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
